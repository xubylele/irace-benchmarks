#Parameters obtained  from https://gcc.gnu.org/onlinedocs/gcc-7.1.0/gcc/Optimize-Options.html#Optimize-Options
# Parameters are ordered according to the list given in the webpage

## Optimization levels
## One of these needs to be specified for enable the use of optimization flags and parameters
optimization_level  "-" c (O1,O2,O3)

############################################
#                                          #
#           parameters for -O1             #
#                                          #
############################################

# Combine increments or decrements of addresses with memory accesses. This pass is always skipped on architectures that do not have instructions to support this. Enabled by default at -O and higher on architectures that support this. 
fauto_inc_dec 	 		"-" 	 c  (fno-auto-inc-dec, fauto-inc-dec)

# Avoid running a pass scanning for opportunities to use “decrement and branch” instructions on a count register instead of generating sequences of instructions that decrement a register, compare it against zero, and then branch based upon the result. This option is only meaningful on architectures that support such instructions, which include x86, PowerPC, IA-64 and S/390. Note that the -fno-branch-count-reg option doesn't remove the decrement and branch instructions from the generated instruction stream introduced by other optimization passes. Enabled by default at -O1 and higher. The default is -fbranch-count-reg. 
fbranch_count_reg 	 "-" 	 c 	 (fno-branch-count-reg, fbranch-count-reg) 

# Tracks stack adjustments (pushes and pops) and stack memory references and then tries to find ways to combine them. Enabled by default at -O1 and higher. 
fcombine_stack_adjustments    "-"   c   (fno-combine-stack-adjustments, fcombine-stack-adjustments)

# After register allocation and post-register allocation instruction splitting, identify arithmetic instructions that compute processor flags similar to a comparison operation based on that arithmetic. If possible, eliminate the explicit comparison operation. This pass only applies to certain targets that cannot explicitly represent the comparison operation before register allocation is complete. Enabled at levels -O, -O2, -O3, -Os. LESLIE: check 
fcompare_elim   "-"   c   (fno-compare-elim, fcompare-elim)

# After register allocation and post-register allocation instruction splitting, perform a copy-propagation pass to try to reduce scheduling dependencies and occasionally eliminate the copy. Enabled at levels -O, -O2, -O3, -Os. 
fcprop_registers 	 "-" 	 c 	 (fno-cprop-registers, fcprop-registers) 

# Perform dead code elimination (DCE) on RTL. Enabled by default at -O and higher. 
fdce 	 		 "-" 	 c 	 (fno-dce, fdce) 

# Always pop the arguments to each function call as soon as that function returns. For machines that must pop arguments after a function call, the compiler normally lets arguments accumulate on the stack for several function calls and pops them all at once. Disabled at levels -O, -O2, -O3, -Os. 
fdefer_pop          "-"     c     (fno-defer-pop, fdefer-pop) 

# If supported for the target machine, attempt to reorder instructions to exploit instruction slots available after delayed branch instructions. Enabled at levels -O, -O2, -O3, -Os. 
fdelayed_branch 	 "-" 	 c 	 (fno-delayed-branch, fdelayed-branch)

# Perform dead store elimination (DSE) on RTL. Enabled by default at -O and higher. 
fdse 	 		 "-" 	 c 	 (fno-dse, fdse)

# Perform a forward propagation pass on RTL. The pass tries to combine two instructions and checks if the result can be simplified. If loop unrolling is active, two passes are performed and the second is scheduled after loop unrolling. This option is enabled by default at optimization levels -O, -O2, -O3, -Os.
fforward_propagate      "-"     c    (fno-forward-propagate, fforward-propagate)

# Do not guess branch probabilities using heuristics.
#GCC uses heuristics to guess branch probabilities if they are not provided by profiling feedback (-fprofile-arcs). These heuristics are based on the control flow graph. If some branch probabilities are specified by __builtin_expect, then the heuristics are used to guess branch probabilities for the rest of the control flow graph, taking the __builtin_expect info into account. The interactions between the heuristics and __builtin_expect can be complex, and in some cases, it may be useful to disable the heuristics so that the effects of __builtin_expect are easier to understand.
#
#The default is -fguess-branch-probability at levels -O, -O2, -O3, -Os. 
fguess_branch_probability 	 "-" 	 c 	 (fno-guess-branch-probability, fguess-branch-probability) 

# Use conditional execution (where available) to transform conditional jumps into branch-less equivalents. Enabled at levels -O, -O2, -O3, -Os. LESLIE: We might delete this? is this complementary to fif_conversion?
fif_conversion2 	 "-" 	 c 	 (fno-if-conversion2, fif-conversion2) #only when chip allows it

#Attempt to transform conditional jumps into branch-less equivalents. This includes use of conditional moves, min, max, set flags and abs instructions, and some tricks doable by standard arithmetics. The use of conditional execution on chips where it is available is controlled by -fif-conversion2. Enabled at levels -O, -O2, -O3, -Os. 
fif_conversion 	 "-" 	 c 	 (fno-if-conversion, fif-conversion) 

# Consider all static functions called once for inlining into their caller even if they are not marked inline. If a call to a given function is integrated, then the function is not output as assembler code in its own right. Enabled at levels -O1, -O2, -O3 and -Os. 
finline_functions_called_once 	 "-" 	 c 	 (fno-inline-functions-called-once, finline-functions-called-once)

# Discover which functions are pure or constant. Enabled by default at -O and higher. 
fipa_pure_const 	 "-" 	 c 	 (fno-ipa-pure-const, fipa-pure-const) 

# Perform interprocedural profile propagation. The functions called only from cold functions are marked as cold. Also functions executed once (such as cold, noreturn, static constructors or destructors) are identified. Cold functions and loop less parts of functions executed once are then optimized for size. Enabled by default at -O and higher. 
fipa_profile    "-"   c   (fno-ipa-profile, fipa-profile)

# Discover which static variables do not escape the compilation unit. Enabled by default at -O and higher. 
fipa_reference 	 "-" 	 c 	 (fno-ipa-reference, fipa-reference) 

# Attempt to merge identical constants (string constants and floating-point constants) across compilation units. This option is the default for optimized compilation if the assembler and linker support it. Use -fno-merge-constants to inhibit this behavior. Enabled at levels -O, -O2, -O3, -Os.
fmerge_constants 	 "-" 	 c 	 (fno-merge-constants, fmerge-constants) 

# Enables the loop invariant motion pass in the RTL loop optimizer. Enabled at level -O1 
fmove_loop_invariants 	 "-" 	 c 	 (fno-move-loop-invariants, fmove-loop-invariants)

# Reorder basic blocks in the compiled function in order to reduce number of taken branches and improve code locality. Enabled at levels -O, -O2, -O3, -Os. 
freorder_blocks 	 "-" 	 c 	 (fno-reorder-blocks, freorder-blocks) 

# Emit function prologues only before parts of the function that need it, rather than at the top of the function. This flag is enabled by default at -O and higher. 
fshrink_wrap    "-"   c   (fno-shrink-wrap, fshrink-wrap)

# Shrink-wrap separate parts of the prologue and epilogue separately, so that those parts are only executed when needed. This option is on by default, but has no effect unless -fshrink-wrap is also turned on and the target supports this. 
fshrink_wrap_separate	"-"	c	(fno-shrink-wrap-separate, fshrink-wrap-separate) | fshrink_wrap %in% c("fshrink-wrap")

# When using a type that occupies multiple registers, such as long long on a 32-bit system, split the registers apart and allocate them independently. This normally generates better code for those types, but may make debugging more difficult. Enabled at levels -O, -O2, -O3, -Os. 
fsplit_wide_types 	 "-" 	 c 	 (fno-split-wide-types, fsplit-wide-types) 

# Propagate information about uses of a value up the definition chain in order to simplify the definitions. For example, this pass strips sign operations if the sign of a value never matters. The flag is enabled by default at -O and higher. 
fssa_backprop   "-"   c   (fno-ssa-backprop, fssa-backprop)

# Perform pattern matching on SSA PHI nodes to optimize conditional code. This pass is enabled by default at -O and higher. 
fssa_phiopt   "-"   c   (fno-ssa-phiopt, fssa-phiopt)

# Perform sparse conditional bit constant propagation on trees and propagate pointer alignment information. This pass only operates on local scalar variables and is enabled by default at -O and higher. It requires that -ftree-ccp is enabled. 
ftree_bit_ccp   "-"   c   (fno-tree-bit-ccp, ftree-bit-ccp) | ftree_ccp %in% c("ftree-ccp")

# Perform sparse conditional constant propagation (CCP) on trees. This pass only operates on local scalar variables and is enabled by default at -O and higher. 
ftree_ccp 	 "-" 	 c 	 (fno-tree-ccp, ftree-ccp) 

# Perform loop header copying on trees. This is beneficial since it increases effectiveness of code motion optimizations. It also saves one jump. This flag is enabled by default at -O and higher. It is not enabled for -Os, since it usually increases code size. 
ftree_ch 	 "-" 	 c 	 (fno-tree-ch, ftree-ch)

# While transforming the program out of the SSA representation, attempt to reduce copying by coalescing versions of different user-defined variables, instead of just compiler temporaries. This may severely limit the ability to debug an optimized program compiled with -fno-var-tracking-assignments. In the negated form, this flag prevents SSA coalescing of user variables. This option is enabled by default if optimization is enabled, and it does very little otherwise. 
ftree_coalesce_vars 	 "-" 	 c 	 (fno-tree-coalesce-vars, ftree-coalesce-vars)

# Perform copy propagation on trees. This pass eliminates unnecessary copy operations. This flag is enabled by default at -O and higher. 
ftree_copy_prop 	 "-" 	 c 	 (fno-tree-copy-prop, ftree-copy-prop) 

# Perform dead code elimination (DCE) on trees. This flag is enabled by default at -O and higher. 
ftree_dce 	 "-" 	 c 	 (fno-tree-dce, ftree-dce) 

#Perform a variety of simple scalar cleanups (constant/copy propagation, redundancy elimination, range propagation and expression simplification) based on a dominator tree traversal. This also performs jump threading (to reduce jumps to jumps). This flag is enabled by default at -O and higher. 
ftree_dominator_opts 	 "-" 	 c 	 (fno-tree-dominator-opts, ftree-dominator-opts) 

# Perform dead store elimination (DSE) on trees. A dead store is a store into a memory location that is later overwritten by another store without any intervening loads. In this case the earlier store can be deleted. This flag is enabled by default at -O and higher. 
ftree_dse 	 "-" 	 c 	 (fno-tree-dse, ftree-dse) 

# Perform forward propagation on trees. This flag is enabled by default at -O and higher. 
ftree_forwprop    "-"   c   (fno-tree-forwprop,ftree-forwprop)

# Perform full redundancy elimination (FRE) on trees. The difference between FRE and PRE is that FRE only considers expressions that are computed on all paths leading to the redundant computation. This analysis is faster than PRE, though it exposes fewer redundancies. This flag is enabled by default at -O and higher. 
ftree_fre 	 "-" 	 c 	 (fno-tree-fre, ftree-fre) 

# Perform hoisting of loads from conditional pointers on trees. This pass is enabled by default at -O and higher. 
ftree_phiprop   "-"   c   (fno-tree-phiprop, ftree-phiprop)

# Perform forward store motion on trees. This flag is enabled by default at -O and higher. 
ftree_sink 	 "-" 	 c 	 (fno-tree-sink, ftree-sink) 

# Perform straight-line strength reduction on trees. This recognizes related expressions involving multiplications and replaces them by less expensive calculations when possible. This is enabled by default at -O and higher. 
ftree_slsr    "-"   c   (fno-tree-slsr, ftree-slsr)

# Perform scalar replacement of aggregates. This pass replaces structure references with scalars to prevent committing structures to memory too early. This flag is enabled by default at -O and higher. 
ftree_sra 	 "-" 	 c 	 (fno-tree-sra, ftree-sra) 

# Perform function-local points-to analysis on trees. This flag is enabled by default at -O and higher. 
ftree_pta   "-"   c   (fno-tree-pta, ftree-pta)

# Perform temporary expression replacement during the SSA->normal phase. Single use/single def temporaries are replaced at their use location with their defining expression. This results in non-GIMPLE code, but gives the expanders much more complex trees to work on resulting in better RTL generation. This is enabled by default at -O and higher. 
ftree_ter 	 "-" 	 c 	 (fno-tree-ter, ftree-ter) 

#This option is left for compatibility reasons. -funit-at-a-time has no effect, while -fno-unit-at-a-time implies -fno-toplevel-reorder and -fno-section-anchors. Enabled by default. 
#funit_at-a-time 	 "-" 	 c 	 (fno-unit-at-a-time, funit-at-a-time) # no effect DO NOT USE

#Don't keep the frame pointer in a register for functions that don't need one. This avoids the instructions to save, set up and restore frame pointers; it also makes an extra register available in many functions. It also makes debugging impossible on some machines. On some machines, such as the VAX, this flag has no effect, because the standard calling sequence automatically handles the frame pointer and nothing is saved by pretending it doesn't exist. The machine-description macro FRAME_POINTER_REQUIRED controls whether a target machine supports this flag. Enabled at levels -O, -O2, -O3, -Os. 
fomit_frame_pointer 	 "-" 	 c 	 (fno-omit-frame-pointer, fomit-frame-pointer)

############################################
#                                          #
#           parameters for -O2             #
#                                          #
############################################

# Perform optimizations that check to see if a jump branches to a location where another comparison subsumed by the first is found. If so, the first branch is redirected to either the destination of the second branch or a point immediately following it, depending on whether the condition is known to be true or false. Enabled at levels -O2, -O3, -Os. 
fthread_jumps 	 "-" 	 c 	 (fno-thread-jumps, fthread-jumps) 

# Align the start of functions to the next power-of-two greater than n, skipping up to n bytes. For instance, -falign-functions=32 aligns functions to the next 32-byte boundary, but -falign-functions=24 aligns to the next 32-byte boundary only if this can be done by skipping 23 bytes or less.
# -fno-align-functions and -falign-functions=1 are equivalent and mean that functions are not aligned.
# Some assemblers only support this flag when n is a power of two; in that case, it is rounded up.
# If n is not specified or is zero, use a machine-dependent default.
# Enabled at levels -O2, -O3. LESLIE: Check if we want to add 0
falign_functions 	"-falign-functions=" 	 o  (0,1,2,4,16,24,32,64) #0: machine dependent, 1:fno-align-functions

# Align branch targets to a power-of-two boundary, for branch targets where the targets can only be reached by jumping, skipping up to n bytes like -falign-functions. In this case, no dummy operations need be executed.
# -fno-align-jumps and -falign-jumps=1 are equivalent and mean that loops are not aligned.
# If n is not specified or is zero, use a machine-dependent default.
# Enabled at levels -O2, -O3. 
falign_jumps 	 	"-falign-jumps=" 	 o  (0,1,2,4,16,24,32,64) #0: machine dependent, 1:fno-align-jumps

# Align loops to a power-of-two boundary, skipping up to n bytes like -falign-functions. If the loops are executed many times, this makes up for any execution of the dummy operations.
# -fno-align-loops and -falign-loops=1 are equivalent and mean that loops are not aligned.
# If n is not specified or is zero, use a machine-dependent default.
# Enabled at levels -O2, -O3. 
falign_loops 	 	"-falign-loops=" 	 o  (0,1,2,4,16,24,32,64) #0: machine dependent, 1:fno-align-loops

# Align all branch targets to a power-of-two boundary, skipping up to n bytes like -falign-functions. This option can easily make code slower, because it must insert dummy operations for when the branch target is reached in the usual flow of the code.
# -fno-align-labels and -falign-labels=1 are equivalent and mean that labels are not aligned.
# If -falign-loops or -falign-jumps are applicable and are greater than this value, then their values are used instead.
# If n is not specified or is zero, use a machine-dependent default which is very likely to be ‘1’, meaning no alignment.
# Enabled at levels -O2, -O3. 
falign_labels 	"-falign-labels=" 	 o  (0,1,2,4,16,24,32,64) #0: machine dependent very likely =1, 1:fno-align-labels, if jumps or loops are bigger their value is used.

# Enable allocation of values to registers that are clobbered by function calls, by emitting extra instructions to save and restore the registers around such calls. Such allocation is done only when it seems to result in better code. This option is always enabled by default on certain machines, usually those which have no call-preserved registers to use instead. Enabled at levels -O2, -O3, -Os. 
fcaller_saves 	 "-" 	 c 	 (fno-caller-saves, fcaller-saves) 

#Perform cross-jumping transformation. This transformation unifies equivalent code and saves code size. The resulting code may or may not perform better than without cross-jumping. Enabled at levels -O2, -O3, -Os.
fcrossjumping 	 "-" 	 c 	 (fno-crossjumping, fcrossjumping)

# In common subexpression elimination (CSE), scan through jump instructions when the target of the jump is not reached by any other path. For example, when CSE encounters an if statement with an else clause, CSE follows the jump when the condition tested is false. Enabled at levels -O2, -O3, -Os.  
fcse_follow_jumps 	 "-" 	 c 	 (fno-cse-follow-jumps, fcse-follow-jumps) 

# This is similar to -fcse-follow-jumps, but causes CSE to follow jumps that conditionally skip over blocks. When CSE encounters a simple if statement with no else clause, -fcse-skip-blocks causes CSE to follow the jump around the body of the if. Enabled at levels -O2, -O3, -Os. 
fcse_skip_blocks 	 "-" 	 c 	 (fno-cse-skip-blocks, fcse-skip-blocks) 

# Assume that programs cannot safely dereference null pointers, and that no code or data element resides at address zero. This option enables simple constant folding optimizations at all optimization levels. In addition, other optimization passes in GCC use this flag to control global dataflow analyses that eliminate useless checks for null pointers; these assume that a memory access to address zero always results in a trap, so that if a pointer is checked after it has already been dereferenced, it cannot be null.
# Note however that in some environments this assumption is not true. Use -fno-delete-null-pointer-checks to disable this optimization for programs that depend on that behavior.
# This option is enabled by default on most targets. On Nios II ELF, it defaults to off. On AVR and CR16, this option is completely disabled.
#Passes that use the dataflow information are enabled independently at different optimization levels. 
fdelete_null_pointer_checks 	"-" 	 c  (fno-delete-null-pointer-checks, fdelete-null-pointer-checks)

# Attempt to convert calls to virtual functions to direct calls. This is done both within a procedure and interprocedurally as part of indirect inlining (-findirect-inlining) and interprocedural constant propagation (-fipa-cp). Enabled at levels -O2, -O3, -Os. 
fdevirtualize   "-"   c   (fno-devirtualize,fdevirtualize)

# Attempt to convert calls to virtual functions to speculative direct calls. Based on the analysis of the type inheritance graph, determine for a given call the set of likely targets. If the set is small, preferably of size 1, change the call into a conditional deciding between direct and indirect calls. The speculative calls enable more optimizations, such as inlining. When they seem useless after further optimization, they are converted back into original form. 
fdevirtualize_speculatively   "-"   c   (fno-devirtualize-speculatively, fdevirtualize-speculatively)

# Perform a number of minor optimizations that are relatively expensive. Enabled at levels -O2, -O3, -Os.
fexpensive_optimizations 	 	"-" 	 c  (fno-expensive-optimizations, fexpensive-optimizations)

# Perform a global common subexpression elimination pass. This pass also performs global constant and copy propagation. Note: When compiling a program using computed gotos, a GCC extension, you may get better run-time performance if you disable the global common subexpression elimination pass by adding -fno-gcse to the command line. Enabled at levels -O2, -O3, -Os. 
fgcse 	 		 "-" 	 c 	 (fno-gcse, fgcse) 

# When -fgcse-lm is enabled, global common subexpression elimination attempts to move loads that are only killed by stores into themselves. This allows a loop containing a load/store sequence to be changed to a load outside the loop, and a copy/store within the loop. Enabled by default when -fgcse is enabled. LESLIE: can it be disabled anyways?
fgcse_lm 		 "-" 	 c 	 (fno-gcse-lm, fgcse-lm) 

# Speculatively hoist loads from both branches of an if-then-else if the loads are from adjacent locations in the same structure and the target architecture has a conditional move instruction. This flag is enabled by default at -O2 and higher. 
fhoist_adjacent_loads   "-"   c   (fno-hoist-adjacent-loads, fhoist-adjacent-loads)

# Integrate functions into their callers when their body is smaller than expected function call code (so overall size of program gets smaller). The compiler heuristically decides which functions are simple enough to be worth integrating in this way. This inlining applies to all functions, even those not declared inline. Enabled at level -O2. 
finline_small_functions 	 "-" 	 c 	 (fno-inline-small-functions, finline-small-functions)

# Inline also indirect calls that are discovered to be known at compile time thanks to previous inlining. This option has any effect only when inlining itself is turned on by the -finline-functions or -finline-small-functions options. Enabled at level -O2
findirect_inlining 	 "-" 	 c 	 (fno-indirect-inlining, findirect-inlining) | (finline_functions %in% c("finline-functions") || finline_small_functions %in% c("finline-small_functions"))

# Perform interprocedural constant propagation. This optimization analyzes the program to determine when values passed to functions are constants and then optimizes accordingly. This optimization can substantially increase performance if the application has constants passed to functions. This flag is enabled by default at -O2, -Os and -O3. 
fipa_cp 	 "-" 	 c 	 (fno-ipa-cp, fipa-cp) 

# When enabled, perform interprocedural bitwise constant propagation. This flag is enabled by default at -O2. It requires that -fipa-cp is enabled.
fipa_bit_cp	"-"	c	(fno-ipa-bit-cp, fipa-bit-cp) | (fipa_cp %in% c("fipa-cp"))

# When enabled, perform interprocedural propagation of value ranges. This flag is enabled by default at -O2. It requires that -fipa-cp is enabled. 
fipa_vrp	"-"	c	(fno-ipa-vrp, fipa-vrp) | (fipa_cp %in% c("fipa-cp"))

# Perform interprocedural scalar replacement of aggregates, removal of unused parameters and replacement of parameters passed by reference by parameters passed by value. Enabled at levels -O2, -O3 and -Os. 
fipa_sra  "-"   c   (fno-ipa-sra, fipa-sra)

# Perform Identical Code Folding for functions and read-only variables. The optimization reduces code size and may disturb unwind stacks by replacing a function by equivalent one with a different name. The optimization works more effectively with link time optimization enabled. Nevertheless the behavior is similar to Gold Linker ICF optimization, GCC ICF works on different levels and thus the optimizations are not same - there are equivalences that are found only by GCC and equivalences found only by Gold. This flag is enabled by default at -O2 and -Os. 
fipa_icf    "-"   c   (fno-ipa-icf,fipa-icf)

# Detect paths that trigger erroneous or undefined behavior due to dereferencing a null pointer. Isolate those paths from the main control flow and turn the statement with erroneous or undefined behavior into a trap. This flag is enabled by default at -O2 and higher and depends on -fdelete-null-pointer-checks also being enabled. 
fisolate_erroneous_paths_dereference    "-"   c   (fno-isolate-erroneous-paths-dereference, fisolate-erroneous-paths-dereference) | fdelete_null_pointer_checks %in% c("fdelete-null-pointer-checks")

# Enable CFG-sensitive rematerialization in LRA. Instead of loading values of spilled pseudos, LRA tries to rematerialize (recalculate) values if it is profitable. Enabled at levels -O2, -O3, -Os. 
flra_remat    "-"   c   (fno-lra-remat, flra-remat)

#Optimize sibling and tail recursive calls. Enabled at levels -O, -O2, -O3, -Os. 
foptimize_sibling_calls 	 "-" 	 c 	 (fno-optimize-sibling-calls, foptimize-sibling-calls)

# Optimize various standard C string functions (e.g. strlen, strchr or strcpy) and their _FORTIFY_SOURCE counterparts into faster alternatives. Enabled at levels -O2, -O3. 
foptimize_strlen	"-"	c	(fno-optimize-strlen, foptimize-strlen)

# Inline parts of functions. This option has any effect only when inlining itself is turned on by the -finline-functions or -finline-small-functions options. Enabled at level -O2. 
fpartial_inlining   "-"   c   (fno-partial-inlining, fpartial-inlining) | finline_functions %in% c("finline-functions") || finline_small_functions %in% c("finline-small-functions")

# Disable any machine-specific peephole optimizations. The difference between -fno-peephole and -fno-peephole2 is in how they are implemented in the compiler; some targets use one, some use the other, a few use both. -fpeephole is enabled by default. -fpeephole2 enabled at levels -O2, -O3, -Os. 
fpeephole 	 "-" 	 c 	 (fno-peephole, fpeephole) 
fpeephole2 	 "-" 	 c 	 (fno-peephole2, fpeephole2) 

#Use the specified algorithm for basic block reordering. The algorithm argument can be ‘simple’, which does not increase code size (except sometimes due to secondary effects like alignment), or ‘stc’, the “software trace cache” algorithm, which tries to put all often executed code together, minimizing the number of branches executed by making extra copies of code. The default is ‘simple’ at levels -O, -Os, and ‘stc’ at levels -O2, -O3. 
freorder_blocks_algorithm   "-freorder-blocks-algorithm="   c   (simple, stc)

#In addition to reordering basic blocks in the compiled function, in order to reduce number of taken branches, partitions hot and cold basic blocks into separate sections of the assembly and .o files, to improve paging and cache locality performance.
#This optimization is automatically turned off in the presence of exception handling, for linkonce sections, for functions with a user-defined section attribute and on any architecture that does not support named sections.
#Enabled for x86 at levels -O2, -O3. 
freorder_blocks_and_partition 	 "-" 	 c 	 (fno-reorder-blocks-and-partition, freorder-blocks-and-partition)

# Reorder functions in the object file in order to improve code locality. This is implemented by using special subsections .text.hot for most frequently executed functions and .text.unlikely for unlikely executed functions. Reordering is done by the linker so object file format must support named sections and linker must place them in a reasonable way.
# Also profile feedback must be available to make this option effective. See -fprofile-arcs for details.
# Enabled at levels -O2, -O3, -Os. 
freorder_functions 	 "-" 	 c 	 (fno-reorder-functions, freorder-functions)

#Re-run common subexpression elimination after loop optimizations are performed. Enabled at levels -O2, -O3, -Os.
frerun_cse_after_loop 	 "-" 	 c 	 (fno-rerun-cse-after-loop, frerun-cse-after-loop) | funroll_loops %in% c("fno-unroll_loops") && funroll_all_loops %in% c("fno-unroll-all-loops")

# Don't schedule instructions across basic blocks. This is normally enabled by default when scheduling before register allocation, i.e. with -fschedule-insns or at -O2 or higher.
fsched_interblock 	 "-" 	 c 	 (fno-sched-interblock, fsched-interblock) 

# Don't allow speculative motion of non-load instructions. This is normally enabled by default when scheduling before register allocation, i.e. with -fschedule-insns or at -O2 or higher. 
fsched_spec 	 "-" 	 c 	 (fno-sched-spec, fsched-spec) 

# If supported for the target machine, attempt to reorder instructions to eliminate execution stalls due to required data being unavailable. This helps machines that have slow floating point or memory load instructions by allowing other instructions to be issued until the result of the load or floating-point instruction is required. Enabled at levels -O2, -O3. 
fschedule_insns 	 "-" 	 c 	 (fno-schedule-insns, fschedule-insns) 

# Similar to -fschedule-insns, but requests an additional pass of instruction scheduling after register allocation has been done. This is especially useful on machines with a relatively small number of registers and where memory load instructions take more than one cycle. Enabled at levels -O2, -O3, -Os. 
fschedule_insns2 	 "-" 	 c 	 (fno-schedule-insns2, fschedule-insns2) 

# Perform merging of narrow stores to consecutive memory addresses. This pass merges contiguous stores of immediate values narrower than a word into fewer wider stores to reduce the number of instructions. This is enabled by default at -O2 and higher as well as -Os. 
fstore_merging	"-"	c	(fno-store-merging, fstore-merging)

#Allow the compiler to assume the strictest aliasing rules applicable to the language being compiled. For C (and C++), this activates optimizations based on the type of expressions. In particular, an object of one type is assumed never to reside at the same address as an object of a different type, unless the types are almost the same. For example, an unsigned int can alias an int, but not a void* or a double. A character type may alias any other type.
#Pay special attention to code like this:
#          union a_union {
#            int i;
#            double d;
#          };
#          
#          int f() {
#            union a_union t;
#            t.d = 3.0;
#            return t.i;
#          }
#The practice of reading from a different union member than the one most recently written to (called “type-punning”) is common. Even with -fstrict-aliasing, type-punning is allowed, provided the memory is accessed through the union type. So, the code above works as expected. See Structures unions enumerations and bit-fields implementation. However, this code might not:
#          int f() {
#            union a_union t;
#            int* ip;
#            t.d = 3.0;
#            ip = &t.i;
#            return *ip;
#          }
#Similarly, access by taking the address, casting the resulting pointer and dereferencing the result has undefined behavior, even if the cast uses a union type, e.g.:
#          int f() {
#            double d = 3.0;
#            return ((union a_union *) &d)->i;
#          }
#The -fstrict-aliasing option is enabled at levels -O2, -O3, -Os. 
fstrict_aliasing 	 "-" 	 c 	 (fno-strict-aliasing, fstrict-aliasing) 

# Allow the compiler to assume strict signed overflow rules, depending on the language being compiled. For C (and C++) this means that overflow when doing arithmetic with signed numbers is undefined, which means that the compiler may assume that it does not happen. This permits various optimizations. For example, the compiler assumes that an expression like i + 10 > i is always true for signed i. This assumption is only valid if signed overflow is undefined, as the expression is false if i + 10 overflows when using twos complement arithmetic. When this option is in effect any attempt to determine whether an operation on signed numbers overflows must be written carefully to not actually involve overflow.
#This option also allows the compiler to assume strict pointer semantics: given a pointer to an object, if adding an offset to that pointer does not produce a pointer to the same object, the addition is undefined. This permits the compiler to conclude that p + u > p is always true for a pointer p and unsigned integer u. This assumption is only valid because pointer wraparound is undefined, as the expression is false if p + u overflows using twos complement arithmetic.
#
#See also the -fwrapv option. Using -fwrapv means that integer signed overflow is fully defined: it wraps. When -fwrapv is used, there is no difference between -fstrict-overflow and -fno-strict-overflow for integers. With -fwrapv certain types of overflow are permitted. For example, if the compiler gets an overflow when doing arithmetic on constants, the overflowed value can still be used with -fwrapv, but not otherwise.
#The -fstrict-overflow option is enabled at levels -O2, -O3, -Os. LESLIE: check if i really want to do this...
fstrict_overflow 	 "-" 	 c 	 (fno-strict-overflow, fstrict-overflow) 

# Perform conditional dead code elimination (DCE) for calls to built-in functions that may set errno but are otherwise side-effect free. This flag is enabled by default at -O2 and higher if -Os is not also specified. 
ftree_builtin_call_dce 	 "-" 	 c 	 (fno-tree-builtin-call-dce, ftree-builtin-call-dce)

# Perform conversion of simple initializations in a switch to initializations from a scalar array. This flag is enabled by default at -O2 and higher.
ftree_switch_conversion 	 "-" 	 c 	 (fno-tree-switch-conversion, ftree-switch-conversion)

# Look for identical code sequences. When found, replace one with a jump to the other. This optimization is known as tail merging or cross jumping. This flag is enabled by default at -O2 and higher. The compilation time in this pass can be limited using max-tail-merge-comparisons parameter and max-tail-merge-iterations parameter. 
ftree_tail_merge    "-"   c   (fno-tree-tail-merge,ftree-tail-merge)

# Perform code hoisting. Code hoisting tries to move the evaluation of expressions executed on all paths to the function exit as early as possible. This is especially useful as a code size optimization, but it often helps for code speed as well. This flag is enabled by default at -O2 and higher. 
fcode_hoisting	"-"	c	(fno-code-hoisting, fcode-hoisting)

# Perform partial redundancy elimination (PRE) on trees. This flag is enabled by default at -O2 and -O3. 
ftree_pre 	 "-" 	 c 	 (fno-tree-pre, ftree-pre) 

# Perform Value Range Propagation on trees. This is similar to the constant propagation pass, but instead of values, ranges of values are propagated. This allows the optimizers to remove unnecessary range checks like array bound checks and null pointer checks. This is enabled by default at -O2 and higher. Null pointer check elimination is only done if -fdelete-null-pointer-checks is enabled. 
ftree_vrp 	 "-" 	 c 	 (fno-tree-vrp, ftree-vrp) 

# Use caller save registers for allocation if those registers are not used by any called function. In that case it is not necessary to save and restore them around calls. This is only possible if called functions are part of same compilation unit as current function and they are compiled before it. Enabled at levels -O2, -O3, -Os. 
fipa_ra   "-"   c   (fno-ipa-ra,fipa-ra)

############################################
#                                          #
#           parameters for -O3             #
#                                          #
############################################

# Consider all functions for inlining, even if they are not declared inline. The compiler heuristically decides which functions are worth integrating in this way. If all calls to a given function are integrated, and the function is declared static, then the function is normally not output as assembler code in its own right. Enabled at level -O3. 
finline_functions 	 "-" 	 c 	 (fno-inline-functions, finline-functions) 

# Move branches with loop invariant conditions out of the loop, with duplicates of the loop on both branches (modified according to result of the condition). 
funswitch_loops 	 "-" 	 c 	 (fno-unswitch-loops, funswitch-loops) 

#Perform predictive commoning optimization, i.e., reusing computations (especially memory loads and stores) performed in previous iterations of loops. This option is enabled at level -O3. 
fpredictive_commoning 	 "-" 	 c 	 (fno-predictive-commoning, fpredictive-commoning) 

# When -fgcse-after-reload is enabled, a redundant load elimination pass is performed after reload. The purpose of this pass is to clean up redundant spilling. 
fgcse_after_reload 	 "-" 	 c 	 (fno-gcse-after-reload, fgcse-after-reload)

# Perform loop vectorization on trees. This flag is enabled by default at -O3 and when -ftree-vectorize is enabled. 
# ALBERTO: how to set the condition?
ftree_loop_vectorize    "-"   c   (fno-tree-loop-vectorize, ftree-loop-vectorize)

# Perform loop distribution of patterns that can be code generated with calls to a library. This flag is enabled by default at -O3.
#This pass distributes the initialization loops and generates a call to memset zero. For example, the loop
#          DO I = 1, N
#            A(I) = 0
#            B(I) = A(I) + I
#          ENDDO
# is transformed to
#
#          DO I = 1, N
#             A(I) = 0
#          ENDDO
#          DO I = 1, N
#             B(I) = A(I) + I
#          ENDDO
#and the initialization loop is transformed into a call to memset zero. 
ftree_loop_distribute_patterns    "-"   c   (fno-tree-loop-distribute-patterns, ftree-loop-distribute-patterns)

# Split paths leading to loop backedges. This can improve dead code elimination and common subexpression elimination. This is enabled by default at -O2 and above. 
fsplit_paths    "-"   c   (fno-split-paths, fsplit-paths)

# Perform basic block vectorization on trees. This flag is enabled by default at -O3 and when -ftree-vectorize is enabled. 
ftree_slp_vectorize   "-"   c   (fno-tree-slp-vectorize, ftree-slp-vectorize) | ftree_vectorize %in% c("fno-tree-vectorize")

# Alter the cost model used for vectorization. The model argument should be one of ‘unlimited’, ‘dynamic’ or ‘cheap’. With the ‘unlimited’ model the vectorized code-path is assumed to be profitable while with the ‘dynamic’ model a runtime check guards the vectorized code-path to enable it only for iteration counts that will likely execute faster than when executing the original scalar loop. The ‘cheap’ model disables vectorization of loops where doing so would be cost prohibitive for example due to required runtime checks for data dependence or alignment but otherwise is equal to the ‘dynamic’ model. The default cost model depends on other optimization flags and is either ‘dynamic’ or ‘cheap’. 
fvect_cost_model 	 "-fvect-cost-model=" 	 c 	 (unlimited, dynamic, cheap) 

# Make partial redundancy elimination (PRE) more aggressive. This flag is enabled by default at -O3. 
ftree_partial_pre   "-"   c   (fno-tree-partial-pre,ftree-partial-pre)

# Peels loops for which there is enough information that they do not roll much (from profile feedback). It also turns on complete loop peeling (i.e. complete removal of loops with small constant number of iterations). Enabled with -fprofile-use. 
# ALBERTO: was commented without [VERSION]
fpeel_loops 	 "-" 	 c 	 (fno-peel-loops, fpeel-loops) 

# Perform function cloning to make interprocedural constant propagation stronger. When enabled, interprocedural constant propagation performs function cloning when externally visible function can be called with constant arguments. Because this optimization can create multiple copies of functions, it may significantly increase code size (see --param ipcp-unit-growth=value). This flag is enabled by default at -O3. 
fipa_cp_clone 	 "-" 	 c 	 (fno-ipa-cp-clone, fipa-cp-clone) 

############################################
#                                          #
#           parameters for -Os             #
#                                          #
############################################

#
# -Os disables the following optimization flags:
#
# -falign-functions  -falign-jumps  -falign-loops 
# -falign-labels  -freorder-blocks  -freorder-blocks-algorithm=stc 
# -freorder-blocks-and-partition  -fprefetch-loop-arrays
#

############################################
#                                          #
#          parameters for -Ofast           #
#                                          #
############################################

# Disregard strict standards compliance. -Ofast enables all -O3 optimizations. It also enables optimizations that are not valid for all standard-compliant programs. It turns on:

# Sets the options -fno-math-errno, -funsafe-math-optimizations, -ffinite-math-only, -fno-rounding-math, -fno-signaling-nans and -fcx-limited-range. This option causes the preprocessor macro __FAST_MATH__ to be defined.
#This option is not turned on by any -O option besides -Ofast since it can result in incorrect output for programs that depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications. LESLIE: Removed because does not seem relevant
#ffast_math 	 	 "-" 	 c 	 (fno-fast-math, ffast-math) 

# and the Fortran-specific -fno-protect-parens and -fstack-arrays (not described in the webpage)

############################################
#                                          #
#              other options               #
#                                          #
############################################

#"Off" disables floating-point expression contraction. "Fast" enables floating-point expression contraction such as forming of fused multiply-add operations if the target has native support for them. "On" enables floating-point expression contraction if allowed by the language standard. This is currently not implemented and treated equal to -ffp-contract=off. The default is -ffp-contract=fast. 
ffp_contract            "-ffp-contract="     c     (fast, off)

# Do not expand any functions inline apart from those marked with the always_inline attribute. This is the default when not optimizing. Single functions can be exempted from inlining by marking them with the noinline attribute. 
finline 	 "-" 	 c 	 (fno-inline, finline) 

# Consider all functions for inlining, even if they are not declared inline. The compiler heuristically decides which functions are worth integrating in this way. If all calls to a given function are integrated, and the function is declared static, then the function is normally not output as assembler code in its own right. Enabled at level -O3. 
fearly_inlining 	 "-" 	 c 	 (fno-early-inlining, fearly-inlining) 

# By default, GCC limits the size of functions that can be inlined. This flag allows coarse control of this limit. n is the size of functions that can be inlined in number of pseudo instructions. Inlining is actually controlled by a number of parameters, which may be specified individually by using --param name=value. The -finline-limit=n option sets some of these parameters as follows:
# max-inline-insns-single
# is set to n/2. 
# max-inline-insns-auto
# is set to n/2.
# See documentation of the individual parameters controlling inlining and for the defaults of these parameters.
# Note: there may be no value to -finline-limit that results in default behavior.
# Note: pseudo instruction represents, in this particular context, an abstract measurement of function's size. In no way does it represent a count of assembly instructions and as such its exact meaning might change from one release to an another.  
finline_limit 	 "-finline-limit=" 	 c 	 (1,2,3,4,5,6,7,8,9,10,20,30,40,50,70,90,100) 

# This is a more fine-grained version of -fkeep-inline-functions, which applies only to functions that are declared using the dllexport attribute or declspec
#fkeep_inline_dllexport    "-"   c   (fno-keep-inline-dllexport, fkeep-inline-dllexport)

# In C, emit static functions that are declared inline into the object file, even if the function has been inlined into all of its callers. This switch does not affect functions using the extern inline extension in GNU C90. In C++, emit any and all inline functions into the object file. 
fkeep_inline_functions 	 "-" 	 c 	 (fno-keep-inline-functions, fkeep-inline-functions) 

# Emit static functions into the object file, even if the function is never used. 
fkeep_static_functions    "-"   c   (fno-keep-static-functions, fkeep-static-functions)

# Emit variables declared static const when optimization isn't turned on, even if the variables aren't referenced. GCC enables this option by default. If you want to force the compiler to check if a variable is referenced, regardless of whether or not optimization is turned on, use the -fno-keep-static-consts option. 
fkeep_static_consts 	 "-" 	 c 	 (fno-keep-static-consts, fkeep-static-consts) 

# Attempt to merge identical constants and identical variables.
# This option implies -fmerge-constants. In addition to -fmerge-constants this considers e.g. even constant initialized arrays or initialized constant variables with integral or floating-point types. Languages like C or C++ require each variable, including multiple instances of the same variable in recursive calls, to have distinct locations, so using this option results in non-conforming behavior. 
fmerge_all_constants 	 "-" 	 c 	 (fno-merge-all-constants, fmerge-all-constants)| fmerge_constants %in% c("fmerge-constants")

# Perform swing modulo scheduling immediately before the first scheduling pass. This pass looks at innermost loops and reorders their instructions by overlapping different iterations. 
fmodulo_sched 	 "-" 	 c 	 (fno-modulo-sched, fmodulo-sched) 

# Perform more aggressive SMS-based modulo scheduling with register moves allowed. By setting this flag certain anti-dependences edges are deleted, which triggers the generation of reg-moves based on the life-range analysis. This option is effective only with -fmodulo-sched enabled.
fmodulo_sched_allow_regmoves 	 "-" 	 c 	 (fno-modulo-sched-allow-regmoves, fmodulo-sched-allow-regmoves) | fmodulo_sched %in% c("fmodulo_sched") 

# Do not put function addresses in registers; make each instruction that calls a constant function contain the function's address explicitly. This option results in less efficient code, but some strange hacks that alter the assembler output may be confused by the optimizations performed when this option is not used. The default is -ffunction-cse 
ffunction_cse 	 "-" 	 c 	 (fno-function-cse, ffunction-cse)

# If the target supports a BSS section, GCC by default puts variables that are initialized to zero into BSS. This can save space in the resulting code. This option turns off this behavior because some programs explicitly rely on variables going to the data section—e.g., so that the resulting executable can find the beginning of that section and/or make assumptions based on that. The default is -fzero-initialized-in-bss. 
fzero_initialized_in_bss 	 "-" 	 c 	 (fno-zero-initialized-in-bss, fzero-initialized-in-bss) 

# When -fgcse-sm is enabled, a store motion pass is run after global common subexpression elimination. This pass attempts to move stores out of loops. When used in conjunction with -fgcse-lm, loops containing a load/store sequence can be changed to a load before the loop and a store after the loop. Not enabled at any optimization level.
fgcse_sm 		 "-" 	 c 	 (fno-gcse-sm, fgcse-sm)

# When -fgcse-las is enabled, the global common subexpression elimination pass eliminates redundant loads that come after stores to the same memory location (both partial and full redundancies). Not enabled at any optimization level.
fgcse_las 		 "-" 	 c 	 (fno-gcse-las, fgcse-las)   

# This option tells the loop optimizer to use language constraints to derive bounds for the number of iterations of a loop. This assumes that loop code does not invoke undefined behavior by for example causing signed integer overflows or out-of-bound array accesses. The bounds for the number of iterations of a loop are used to guide loop unrolling and peeling and loop exit test optimizations. This option is enabled by default. 
faggressive_loop_optimizations    "-"   c   (fno-aggressive-loop-optimizations, faggressive-loop-optimizations)

# This option tells the compiler that variables declared in common blocks (e.g. Fortran) may later be overridden with longer trailing arrays. This prevents certain optimizations that depend on knowing the array bounds. 
funconstrained_commons    "-"   c   (fno-unconstrained-commons, funconstrained-commons)

# The C++ ABI requires multiple entry points for constructors and destructors: one for a base subobject, one for a complete object, and one for a virtual destructor that calls operator delete afterwards. For a hierarchy with virtual bases, the base and complete variants are clones, which means two copies of the function. With this option, the base and complete variants are changed to be thunks that call a common implementation. Enabled by -Os. 
fdeclone_ctor_dtor    "-"   c   (fno-declone-ctor-dtor, fdeclone-ctor-dtor)  

# Stream extra information needed for aggressive devirtualization when running the link-time optimizer in local transformation mode. This option enables more devirtualization but significantly increases the size of streamed data. For this reason it is disabled by default. 
fdevirtualize_at_ltrans   "-"   c   (fno-devirtualize-at-ltrans, fdevirtualize-at-ltrans)

# Attempt to remove redundant extension instructions. This is especially helpful for the x86-64 architecture, which implicitly zero-extends in 64-bit registers after writing to their lower 32-bit half. Enabled for Alpha, AArch64 and x86 at levels -O2, -O3, -Os. 
free    "-"   c   (fno-ree, free)

# In C++ the value of an object is only affected by changes within its lifetime: when the constructor begins, the object has an indeterminate value, and any changes during the lifetime of the object are dead when the object is destroyed. Normally dead store elimination will take advantage of this; if your code relies on the value of the object storage persisting beyond the lifetime of the object, you can use this flag to disable this optimization. To preserve stores before the constructor starts (e.g. because your operator new clears the object storage) but still treat the object as dead after the destructor you, can use -flifetime-dse=1. The default behavior can be explicitly selected with -flifetime-dse=2. -flifetime-dse=0 is equivalent to -fno-lifetime-dse. 
flifetime_dse   "-flifetime-dse="   c   (0,1,2)

# Attempt to decrease register pressure through register live range shrinkage. This is helpful for fast processors with small or moderate size register sets. 
flive_range_shrinkage   "-"   c   (fno-live-range-shrinkage, flive-range-shrinkage)

# Use the specified coloring algorithm for the integrated register allocator. The algorithm argument can be ‘priority’, which specifies Chow's priority coloring, or ‘CB’, which specifies Chaitin-Briggs coloring. Chaitin-Briggs coloring is not implemented for all architectures, but for those targets that do support it, it is the default because it generates better code. 
fira_algorithm 	 "-fira-algorithm=" 	 c 	 (priority, CB)

# Use specified regions for the integrated register allocator. The region argument should be one of the following:
# ‘all’ Use all loops as register allocation regions. This can give the best results for machines with a small and/or irregular register set. 
# ‘mixed’ Use all loops except for loops with small register pressure as the regions. This value usually gives the best results in most cases and for most architectures, and is enabled by default when compiling with optimization for speed (-O, -O2, ...). 
# ‘one’ Use all functions as a single region. This typically results in the smallest code size, and is enabled by default for -Os or -O0.
fira_region 	 "-fira-region=" 	 c 	 (all, mixed, one) 

# Use IRA to evaluate register pressure in the code hoisting pass for decisions to hoist expressions. This option usually results in smaller code, but it can slow the compiler down. This option is enabled at level -Os for all targets. 
fira_hoist_pressure   "-"   c   (fno-ira-hoist-pressure,fira-hoist-pressure)

#Use IRA to evaluate register pressure in loops for decisions to move loop invariants. This option usually results in generation of faster and smaller code on machines with large register files (>= 32 registers), but it can slow the compiler down. This option is enabled at level -O3 for some targets.
fira_loop_pressure    "-"   c   (fno-ira-loop-pressure,fira-loop-pressure)

# Disable sharing of stack slots used for saving call-used hard registers living through a call. Each hard register gets a separate stack slot, and as a result function stack frames are larger. 
fira_share_save_slots 	 "-" 	 c 	 (fno-ira-share-save-slots, fira-share-save-slots)

# Disable sharing of stack slots allocated for pseudo-registers. Each pseudo-register that does not get a hard register gets a separate stack slot, and as a result function stack frames are larger. 
fira_share_spill_slots 	 "-" 	 c 	 (fno-ira-share-spill-slots, fira-share-spill-slots)

# Enable register pressure sensitive insn scheduling before register allocation. This only makes sense when scheduling before register allocation is enabled, i.e. with -fschedule-insns or at -O2 or higher. Usage of this option can improve the generated code and decrease its size by preventing register pressure increase above the number of available hard registers and subsequent spills in register allocation. 
fsched_pressure   "-"   c   (fno-sched-pressure,fsched-pressure) | fschedule_insns %in% c("fschedule-insns")

# Allow speculative motion of some load instructions. This only makes sense when scheduling before register allocation, i.e. with -fschedule-insns or at -O2 or higher. 
fsched_spec_load 	 "-" 	 c 	 (fno-sched-spec-load, fsched-spec-load) | fschedule_insns %in% c("fschedule-insns")

# Allow speculative motion of more load instructions. This only makes sense when scheduling before register allocation, i.e. with -fschedule-insns or at -O2 or higher.
fsched_spec_load_dangerous 	 "-" 	 c 	 (fno-sched-spec-load-dangerous, fsched-spec-load-dangerous) | fschedule_insns %in% c("fschedule-insns")

# Define how many insns (if any) can be moved prematurely from the queue of stalled insns into the ready list during the second scheduling pass. -fno-sched-stalled-insns means that no insns are moved prematurely, -fsched-stalled-insns=0 means there is no limit on how many queued insns can be moved prematurely. -fsched-stalled-insns without a value is equivalent to -fsched-stalled-insns=1. LESLIE: Are these numbers fine?
fsched_stalled_insns	 "-" 	 c 	 (fno-sched-stalled-insns, fsched-stalled-insns=0,fsched-stalled-insns=1,fsched-stalled-insns=2,fsched-stalled-insns=3,fsched-stalled-insns=4,fsched-stalled-insns=5) 

# Define how many insn groups (cycles) are examined for a dependency on a stalled insn that is a candidate for premature removal from the queue of stalled insns. This has an effect only during the second scheduling pass, and only if -fsched-stalled-insns is used. -fno-sched-stalled-insns-dep is equivalent to -fsched-stalled-insns-dep=0. -fsched-stalled-insns-dep without a value is equivalent to -fsched-stalled-insns-dep=1. LESLIE: Are these numbers right? 
fsched_stalled_insns_dep 	 "-fsched-stalled-insns-dep=" 	 c 	 (0,1,2,3,4,5) 

# When scheduling after register allocation, use superblock scheduling. This allows motion across basic block boundaries, resulting in faster schedules. This option is experimental, as not all machine descriptions used by GCC model the CPU closely enough to avoid unreliable results from the algorithm. This only makes sense when scheduling after register allocation, i.e. with -fschedule-insns2 or at -O2 or higher. 
fsched2_use_superblocks 	 "-" 	 c 	 (fno-sched2-use-superblocks, fsched2-use-superblocks) | fschedule_insns2 %in% c("fschedule-insns2")

# Enable the group heuristic in the scheduler. This heuristic favors the instruction that belongs to a schedule group. This is enabled by default when scheduling is enabled, i.e. with -fschedule-insns or -fschedule-insns2 or at -O2 or higher. 
fsched_group_heuristic    "-"   c   (fno-sched-group-heuristic,fsched-group-heuristic)

# Enable the critical-path heuristic in the scheduler. This heuristic favors instructions on the critical path. This is enabled by default when scheduling is enabled, i.e. with -fschedule-insns or -fschedule-insns2 or at -O2 or higher.
fsched_critical_path_heuristic    "-"   c   (fno-sched-critical-path-heuristic,fsched-critical-path-heuristic)

# Enable the speculative instruction heuristic in the scheduler. This heuristic favors speculative instructions with greater dependency weakness. This is enabled by default when scheduling is enabled, i.e. with -fschedule-insns or -fschedule-insns2 or at -O2 or higher. 
fsched_spec_insn_heuristic    "-"     c   (fno-sched-spec-insn-heuristic, fsched-spec-insn-heuristic)

# Enable the rank heuristic in the scheduler. This heuristic favors the instruction belonging to a basic block with greater size or frequency. This is enabled by default when scheduling is enabled, i.e. with -fschedule-insns or -fschedule-insns2 or at -O2 or higher. 
fsched_rank_heuristic   "-"   c   (fno-sched-rank-heuristic, fsched-rank-heuristic)

# Enable the last-instruction heuristic in the scheduler. This heuristic favors the instruction that is less dependent on the last instruction scheduled. This is enabled by default when scheduling is enabled, i.e. with -fschedule-insns or -fschedule-insns2 or at -O2 or higher. 
fsched_last_insn_heuristic    "-"   c   (fno-sched-last-insn-heuristic, fsched-last-insn-heuristic)

# Enable the dependent-count heuristic in the scheduler. This heuristic favors the instruction that has more instructions depending on it. This is enabled by default when scheduling is enabled, i.e. with -fschedule-insns or -fschedule-insns2 or at -O2 or higher. 
fsched_dep_count_heuristic    "-"   c   (fno-sched-dep-count-heuristic, fsched-dep-count-heuristic)

# Modulo scheduling is performed before traditional scheduling. If a loop is modulo scheduled, later scheduling passes may change its schedule. Use this option to control that behavior. 
freschedule_modulo_scheduled_loops 	 "-" 	 c 	 (fno-reschedule-modulo-scheduled-loops, freschedule-modulo-scheduled-loops) 

# Schedule instructions using selective scheduling algorithm. Selective scheduling runs instead of the first scheduler pass. 
fselective_scheduling 	 "-" 	 c 	 (fno-selective-scheduling, fselective-scheduling) 

# Schedule instructions using selective scheduling algorithm. Selective scheduling runs instead of the second scheduler pass. 
fselective_scheduling2 	 "-" 	 c 	 (fno-selective-scheduling2, fselective-scheduling2) 

# Enable software pipelining of innermost loops during selective scheduling. This option has no effect unless one of -fselective-scheduling or -fselective-scheduling2 is turned on. 
fsel_sched_pipelining 	 "-" 	 c 	 (fno-sel-sched-pipelining, fsel-sched-pipelining) | fselective_scheduling %in% c("fselective-scheduling") || fselective_scheduling2 %in% c("fselective-scheduling2")

# When pipelining loops during selective scheduling, also pipeline outer loops. This option has no effect unless -fsel-sched-pipelining is turned on. 
fsel_sched_pipelining_outer_loops 	 "-" 	 c 	 (fno-sel-sched-pipelining-outer-loops, fsel-sched-pipelining-outer-loops) | fsel_sched_pipelining  %in% c("fsel-sched-pipelining")

# Some object formats, like ELF, allow interposing of symbols by the dynamic linker. This means that for symbols exported from the DSO, the compiler cannot perform interprocedural propagation, inlining and other optimizations in anticipation that the function or variable in question may change. While this feature is useful, for example, to rewrite memory allocation functions by a debugging implementation, it is expensive in the terms of code quality. With -fno-semantic-interposition the compiler assumes that if interposition happens for functions the overwriting function will have precisely the same semantics (and side effects). Similarly if interposition happens for variables, the constructor of the variable will be the same. The flag has no effect for functions explicitly declared inline (where it is never allowed for interposition to change semantics) and for symbols explicitly declared weak. 
fsemantic_interposition   "-"   c   (fno-semantic-interposition, fsemantic-interposition)

# Attempt to minimize stack usage. The compiler attempts to use less stack space, even if that makes the program slower. This option implies setting the large-stack-frame parameter to 100 and the large-stack-frame-growth parameter to 400. # ALBERTO: how to set them???
fconserve_stack 	 "-" 	 c 	 (fno-conserve-stack, fconserve-stack) 

# Perform reassociation on trees. This flag is enabled by default at -O and higher. 
ftree_reassoc 	 "-" 	 c 	 (fno-tree-reassoc, ftree-reassoc) 

# Perform interprocedural pointer analysis and interprocedural modification and reference analysis. This option can cause excessive memory and compile-time usage on large compilation units. It is not enabled by default at any optimization level. LESLIE: Maybe we dont use this?
fipa_pta 	 "-" 	 c 	 (fno-ipa-pta, fipa-pta) 

# Detect paths that trigger erroneous or undefined behavior due a null value being used in a way forbidden by a returns_nonnull or nonnull attribute. Isolate those paths from the main control flow and turn the statement with erroneous or undefined behavior into a trap. This is not currently enabled, but may be enabled by -O2 in the future. 
# ALBERTO: what to do with this one?
#fisolate_erroneous_paths_attribute    "-"   c   (fno-isolate-erroneous-paths-attribute, fisolate-erroneous-paths-attribute)

# Perform loop optimizations on trees. This flag is enabled by default at -O and higher. 
ftree_loop_optimize 	 "-" 	 c 	 (fno-tree-loop-optimize, ftree-loop-optimize) 

#Perform loop nest optimizations. Same as -floop-nest-optimize. To use this code transformation, GCC has to be configured with --with-isl to enable the Graphite loop transformation infrastructure. # ALBERTO: how?
#LESLIE: check these need --with-ppl --with-cloog
#ftree_loop_linear 	 "-" 	 c 	 (fno-tree-loop-linear, ftree-loop-linear) 
#floop_interchange 	 "-" 	 c 	 (fno-loop-interchange, floop-interchange) 
#floop_strip_mine 	 "-" 	 c 	 (fno-loop-strip-mine, floop-strip-mine) 
#floop_block 	 "-" 	 c 	 (fno-loop-block, floop-block) 
#floop_unroll_and_jam    "-"   c   (fno-loop-unroll-and-jam, floop-unroll-and-jam)

# Enable the identity transformation for graphite. For every SCoP we generate the polyhedral representation and transform it back to gimple. Using -fgraphite-identity we can check the costs or benefits of the GIMPLE -> GRAPHITE -> GIMPLE transformation. Some minimal optimizations are also performed by the code generator isl, like index splitting and dead code elimination in loops. LESLIE: check
#fgraphite_identity    "-"   c   (fno-graphite-identity,fgraphite-identity)

# Enable the isl based loop nest optimizer. This is a generic loop nest optimizer based on the Pluto optimization algorithms. It calculates a loop structure optimized for data-locality and parallelism. This option is experimental.  LESLIE: check
#floop_nest_optimize   "-"   c   (fno-loop-nest-optimize, floop-nest-optimize)

# Use the Graphite data dependence analysis to identify loops that can be parallelized. Parallelize all the loops that can be analyzed to not contain loop carried dependences without checking that it is profitable to parallelize the loops. LESLIE: check
#floop_parallelize_all   "-"   c   (fno-loop-parallelize-all, floop-parallelize-all)

# Attempt to transform conditional jumps in the innermost loops to branch-less equivalents. The intent is to remove control-flow from the innermost loops in order to improve the ability of the vectorization pass to handle these loops. This is enabled by default if vectorization is enabled.
ftree_loop_if_convert   "-"   c   (fno-tree-loop-if-convert, ftree-loop-if-convert)

# Perform loop distribution. This flag can improve cache performance on big loop bodies and allow further loop optimizations, like parallelization or vectorization, to take place. For example, the loop
#          DO I = 1, N
#            A(I) = B(I) + C
#            D(I) = E(I) * F
#          ENDDO
# is transformed to
#
#          DO I = 1, N
#             A(I) = B(I) + C
#          ENDDO
#          DO I = 1, N
#             D(I) = E(I) * F
#          ENDDO
ftree_loop_distribution 	 "-" 	 c 	 (fno-tree-loop-distribution, ftree-loop-distribution) 

#Perform loop invariant motion on trees. This pass moves only invariants that are hard to handle at RTL level (function calls, operations that expand to nontrivial sequences of insns). With -funswitch-loops it also moves operands of conditions that are invariant out of the loop, so that we can use just trivial invariantness analysis in loop unswitching. The pass also includes store motion. 
ftree_loop_im 	 "-" 	 c 	 (fno-tree-loop-im, ftree-loop-im) 

# Create a canonical counter for number of iterations in loops for which determining number of iterations requires complicated analysis. Later optimizations then may determine the number easily. Useful especially in connection with unrolling. 
ftree_loop_ivcanon 	 "-" 	 c 	 (fno-tree-loop-ivcanon, ftree-loop-ivcanon) 

# Perform induction variable optimizations (strength reduction, induction variable merging and induction variable elimination) on trees. 
fivopts 	 "-" 	 c 	 (fno-ivopts, fivopts) 

# Parallelize loops, i.e., split their iteration space to run in n threads. This is only possible for loops whose iterations are independent and can be arbitrarily reordered. The optimization is only profitable on multiprocessor machines, for loops that are CPU-intensive, rather than constrained e.g. by memory bandwidth. This option implies -pthread, and thus is only supported on targets that have support for -pthread. LESLIE: Are these values ok? CHECK
# ALBERTO: n is the number of threads, I guess it's not something we have to tune unless we have some choice such as (2,4,8,...)
#ftree_parallelize_loops   "-ftree-parallelize-loops="   c   (2,3,4,5) 

# Perform vectorization on trees. This flag enables -ftree-loop-vectorize and -ftree-slp-vectorize if not explicitly specified. 
#ftree_vectorize 	 "-" 	 c 	 (fno-tree-vectorize, ftree-vectorize) | ftree_loop_vectorize %in% c("ftree-loop-vectorize") && ftree_slp_vectorize %in% c("ftree-slp-vectorize")
ftree_vectorize 	 "-" 	 c 	 (fno-tree-vectorize, ftree-vectorize) 

# Enables expression of values of induction variables in later iterations of the unrolled loop using the value in the first iteration. This breaks long dependency chains, thus improving efficiency of the scheduling passes. A combination of -fweb and CSE is often sufficient to obtain the same effect. However, that is not reliable in cases where the loop body is more complicated than a single basic block. It also does not work at all on some architectures due to restrictions in the CSE pass. This optimization is enabled by default. 
fsplit_ivs_in_unroller 	 "-" 	 c 	 (fno-split-ivs-in-unroller, fsplit-ivs-in-unroller)  

# With this option, the compiler creates multiple copies of some local variables when unrolling a loop, which can result in superior code. 
fvariable_expansion_in_unroller 	 "-" 	 c 	 (fno-variable-expansion-in-unroller, fvariable-expansion-in-unroller) 

# If supported by the target machine, generate instructions to prefetch memory to improve the performance of loops that access large arrays. This option may generate better or worse code; results are highly dependent on the structure of loops within the source code. Disabled at level -Os. 
fprefetch_loop_arrays 	 "-" 	 c 	 (fno-prefetch-loop-arrays, fprefetch-loop-arrays) 

#Do not substitute constants for known return value of formatted output functions such as sprintf, snprintf, vsprintf, and vsnprintf (but not printf of fprintf). This transformation allows GCC to optimize or even eliminate branches based on the known return value of these functions called with arguments that are either constant, or whose values are known to be in a range that makes determining the exact return value possible. For example, when -fprintf-return-value is in effect, both the branch and the body of the if statement (but not the call to snprint) can be optimized away when i is a 32-bit or smaller integer because the return value is guaranteed to be at most 8.
#
#char buf[9];
#if (snprintf (buf, "%08x", i) >= sizeof buf)
#  …
#
#The -fprintf-return-value option relies on other optimizations and yields best results with -O2. It works in tandem with the -Wformat-overflow and -Wformat-truncation options. The -fprintf-return-value option is enabled by default. 
fprintf_return_value	"-"	c	(fno-printf-return-value, fprintf-return-value)

# If this option is enabled, the compiler tries to avoid unnecessarily overaligning functions. It attempts to instruct the assembler to align by the amount specified by -falign-functions, but not to skip more bytes than the size of the function. 
flimit_function_alignment	"-"	c	(fno-limit-function-alignment, flimit-function-alignment)

# Do not reorder top-level functions, variables, and asm statements. Output them in the same order that they appear in the input file. When this option is used, unreferenced static variables are not removed. This option is intended to support existing code that relies on a particular ordering. For new code, it is better to use attributes when possible.
# Enabled at level -O0. When disabled explicitly, it also implies -fno-section-anchors, which is otherwise enabled at -O0 on some targets. LESLIE: seems to be better not to used it 
# fno_toplevel_reorder 	 "-" 	 c 	 (fno-toplevel-reorder, ftoplevel-reorder) 

# Constructs webs as commonly used for register allocation purposes and assign each web individual pseudo register. This allows the register allocation pass to operate on pseudos directly, but also strengthens several other optimization passes, such as CSE, loop optimizer and trivial dead code remover. It can, however, make debugging impossible, since variables no longer stay in a “home register”.
# Enabled by default with -funroll-loops.
fweb 	 "-" 	 c 	 (fno-web, fweb)  | funroll_loops %in% c("fno-unroll_loops") && funroll_all_loops %in% c("fno-unroll-all-loops")

# Assume that the current compilation unit represents the whole program being compiled. All public functions and variables with the exception of main and those merged by attribute externally_visible become static functions and in effect are optimized more aggressively by interprocedural optimizers.
#This option should not be used in combination with -flto. Instead relying on a linker plugin should provide safer and more precise information. LESLIE: Check that flto is not used
fwhole_program 	 "-" 	 c 	 (fno-whole-program, fwhole-program) | flto %in% c("fno-lto")

# This option runs the standard link-time optimizer. When invoked with source code, it generates GIMPLE (one of GCC's internal representations) and writes it to special ELF sections in the object file. When the object files are linked together, all the function bodies are read from these ELF sections and instantiated as if they had been part of the same translation unit.
#To use the link-time optimizer, -flto and optimization options should be specified at compile time and during the final link. It is recommended that you compile all the files participating in the same link with the same options and also specify those options at link time. For example:
#
#          gcc -c -O2 -flto foo.c
#          gcc -c -O2 -flto bar.c
#          gcc -o myprog -flto -O2 foo.o bar.o
#The first two invocations to GCC save a bytecode representation of GIMPLE into special ELF sections inside foo.o and bar.o. The final invocation reads the GIMPLE bytecode from foo.o and bar.o, merges the two files into a single internal image, and compiles the result as usual. Since both foo.o and bar.o are merged into a single image, this causes all the interprocedural analyses and optimizations in GCC to work across the two files as if they were a single one. This means, for example, that the inliner is able to inline functions in bar.o into functions in foo.o and vice-versa.
#
#Another (simpler) way to enable link-time optimization is:
#
#          gcc -o myprog -flto -O2 foo.c bar.c
#The above generates bytecode for foo.c and bar.c, merges them together into a single GIMPLE representation and optimizes them as usual to produce myprog.
#
#The only important thing to keep in mind is that to enable link-time optimizations you need to use the GCC driver to perform the link step. GCC then automatically performs link-time optimization if any of the objects involved were compiled with the -flto command-line option. You generally should specify the optimization options to be used for link-time optimization though GCC tries to be clever at guessing an optimization level to use from the options used at compile time if you fail to specify one at link time. You can always override the automatic decision to do link-time optimization at link time by passing -fno-lto to the link command.
#
#To make whole program optimization effective, it is necessary to make certain whole program assumptions. The compiler needs to know what functions and variables can be accessed by libraries and runtime outside of the link-time optimized unit. When supported by the linker, the linker plugin (see -fuse-linker-plugin) passes information to the compiler about used and externally visible symbols. When the linker plugin is not available, -fwhole-program should be used to allow the compiler to make these assumptions, which leads to more aggressive optimization decisions.
#
#When -fuse-linker-plugin is not enabled, when a file is compiled with -flto, the generated object file is larger than a regular object file because it contains GIMPLE bytecodes and the usual final code (see -ffat-lto-objects. This means that object files with LTO information can be linked as normal object files; if -fno-lto is passed to the linker, no interprocedural optimizations are applied. Note that when -fno-fat-lto-objects is enabled the compile stage is faster but you cannot perform a regular, non-LTO link on them.
#
#Additionally, the optimization flags used to compile individual files are not necessarily related to those used at link time. For instance,
#
#          gcc -c -O0 -ffat-lto-objects -flto foo.c
#          gcc -c -O0 -ffat-lto-objects -flto bar.c
#          gcc -o myprog -O3 foo.o bar.o
#This produces individual object files with unoptimized assembler code, but the resulting binary myprog is optimized at -O3. If, instead, the final binary is generated with -fno-lto, then myprog is not optimized.
#
#When producing the final binary, GCC only applies link-time optimizations to those files that contain bytecode. Therefore, you can mix and match object files and libraries with GIMPLE bytecodes and final object code. GCC automatically selects which files to optimize in LTO mode and which files to link without further processing.
#
#There are some code generation flags preserved by GCC when generating bytecodes, as they need to be used during the final link stage. Generally options specified at link time override those specified at compile time.
#
#If you do not specify an optimization level option -O at link time, then GCC uses the highest optimization level used when compiling the object files.
#
#Currently, the following options and their settings are taken from the first object file that explicitly specifies them: -fPIC, -fpic, -fpie, -fcommon, -fexceptions, -fnon-call-exceptions, -fgnu-tm and all the -m target flags.
#
#Certain ABI-changing flags are required to match in all compilation units, and trying to override this at link time with a conflicting value is ignored. This includes options such as -freg-struct-return and -fpcc-struct-return.
#
#Other options such as -ffp-contract, -fno-strict-overflow, -fwrapv, -fno-trapv or -fno-strict-aliasing are passed through to the link stage and merged conservatively for conflicting translation units. Specifically -fno-strict-overflow, -fwrapv and -fno-trapv take precedence; and for example -ffp-contract=off takes precedence over -ffp-contract=fast. You can override them at link time.
#
#If LTO encounters objects with C linkage declared with incompatible types in separate translation units to be linked together (undefined behavior according to ISO C99 6.2.7), a non-fatal diagnostic may be issued. The behavior is still undefined at run time. Similar diagnostics may be raised for other languages.
#
#Another feature of LTO is that it is possible to apply interprocedural optimizations on files written in different languages:
#
#          gcc -c -flto foo.c
#          g++ -c -flto bar.cc
#          gfortran -c -flto baz.f90
#          g++ -o myprog -flto -O3 foo.o bar.o baz.o -lgfortran
#Notice that the final link is done with g++ to get the C++ runtime libraries and -lgfortran is added to get the Fortran runtime libraries. In general, when mixing languages in LTO mode, you should use the same link command options as when mixing languages in a regular (non-LTO) compilation.
#
#If object files containing GIMPLE bytecode are stored in a library archive, say libfoo.a, it is possible to extract and use them in an LTO link if you are using a linker with plugin support. To create static libraries suitable for LTO, use gcc-ar and gcc-ranlib instead of ar and ranlib; to show the symbols of object files with GIMPLE bytecode, use gcc-nm. Those commands require that ar, ranlib and nm have been compiled with plugin support. At link time, use the the flag -fuse-linker-plugin to ensure that the library participates in the LTO optimization process:
#
#          gcc -o myprog -O2 -flto -fuse-linker-plugin a.o b.o -lfoo
#With the linker plugin enabled, the linker extracts the needed GIMPLE files from libfoo.a and passes them on to the running GCC to make them part of the aggregated GIMPLE image to be optimized.
#
#If you are not using a linker with plugin support and/or do not enable the linker plugin, then the objects inside libfoo.a are extracted and linked as usual, but they do not participate in the LTO optimization process. In order to make a static library suitable for both LTO optimization and usual linkage, compile its object files with -flto -ffat-lto-objects.
#
#Link-time optimizations do not require the presence of the whole program to operate. If the program does not require any symbols to be exported, it is possible to combine -flto and -fwhole-program to allow the interprocedural optimizers to use more aggressive assumptions which may lead to improved optimization opportunities. Use of -fwhole-program is not needed when linker plugin is active (see -fuse-linker-plugin).
#
#The current implementation of LTO makes no attempt to generate bytecode that is portable between different types of hosts. The bytecode files are versioned and there is a strict version check, so bytecode files generated in one version of GCC do not work with an older or newer version of GCC.
#
#Link-time optimization does not work well with generation of debugging information. Combining -flto with -g is currently experimental and expected to produce unexpected results.
#
#If you specify the optional n, the optimization and code generation done at link time is executed in parallel using n parallel jobs by utilizing an installed make program. The environment variable MAKE may be used to override the program used. The default value for n is 1.
#
#You can also specify -flto=jobserver to use GNU make's job server mode to determine the number of parallel jobs. This is useful when the Makefile calling GCC is already executing in parallel. You must prepend a ‘+’ to the command recipe in the parent Makefile for this to work. This option likely only works if MAKE is GNU make. LESLIE: CHECK that fno-lto exists! ALBERTO: seems the case
flto    "-"   c   ("flto","fno-lto")

# Specify the partitioning algorithm used by the link-time optimizer. The value is either ‘1to1’ to specify a partitioning mirroring the original source files or ‘balanced’ to specify partitioning into equally sized chunks (whenever possible) or ‘max’ to create new partition for every symbol where possible. Specifying ‘none’ as an algorithm disables partitioning and streaming completely. The default value is ‘balanced’. While ‘1to1’ can be used as an workaround for various code ordering issues, the ‘max’ partitioning is intended for internal testing only. The value ‘one’ specifies that exactly one partition should be used while the value ‘none’ bypasses partitioning and executes the link-time optimization step directly from the WPA phase. 
flto_partition    "-flto-partition="   c   (1to1,balanced,max,none) | flto %in% c("flto")

# Enable streaming of mangled types names of C++ types and their unification at link time. This increases size of LTO object files, but enables diagnostics about One Definition Rule violations. 
flto_odr_type_merging   "-"   c   (fno-lto-odr-type-merging, flto-odr-type-merging) | flto %in% c("flto")

# This option specifies the level of compression used for intermediate language written to LTO object files, and is only meaningful in conjunction with LTO mode (-flto). Valid values are 0 (no compression) to 9 (maximum compression). Values outside this range are clamped to either 0 or 9. If the option is not given, a default balanced compression setting is used. 
flto_compression_level  "-flto-compression-level="   i   (0,9) | flto %in% c("flto")

# Enables the use of a linker plugin during link-time optimization. This option relies on plugin support in the linker, which is available in gold or in GNU ld 2.21 or newer.
#This option enables the extraction of object files with GIMPLE bytecode out of library archives. This improves the quality of optimization by exposing more code to the link-time optimizer. This information specifies what symbols can be accessed externally (by non-LTO object or during dynamic linking). Resulting code quality improvements on binaries (and shared libraries that use hidden visibility) are similar to -fwhole-program. See -flto for a description of the effect of this flag and how to use it.
#
#This option is enabled by default when LTO support in GCC is enabled and GCC was configured for use with a linker supporting plugins (GNU ld 2.21 or newer or gold). 
fuse_linker_plugin    "-"   c   (fno-use-linker-plugin, fuse-linker-plugin) | flto %in% c("flto")

# Fat LTO objects are object files that contain both the intermediate language and the object code. This makes them usable for both LTO linking and normal linking. This option is effective only when compiling with -flto and is ignored at link time.
# -fno-fat-lto-objects improves compilation time over plain LTO, but requires the complete toolchain to be aware of LTO. It requires a linker with linker plugin support for basic functionality. Additionally, nm, ar and ranlib need to support linker plugins to allow a full-featured build environment (capable of building static libraries etc). GCC provides the gcc-ar, gcc-nm, gcc-ranlib wrappers to pass the right options to these tools. With non fat LTO makefiles need to be modified to use them.
#The default is -fno-fat-lto-objects on targets with linker plugin support. 
ffat_lto_objects    "-"   c   (fno-fat-lto-objects, ffat-lto-objects)

# Profiles collected using an instrumented binary for multi-threaded programs may be inconsistent due to missed counter updates. When this option is specified, GCC uses heuristics to correct or smooth out such inconsistencies. By default, GCC emits an error message when an inconsistent profile is detected.
#fprofile_correction 	 "-" 	 c 	 (fno-profile-correction, fprofile-correction) 

#Enable profile feedback-directed optimizations, and the following optimizations which are generally profitable only with profile feedback available: -fbranch-probabilities, -fvpt, -funroll-loops, -fpeel-loops, -ftracer, -ftree-vectorize, and ftree-loop-distribute-patterns.
#
#Before you can use this option, you must first generate profiling information. See https://gcc.gnu.org/onlinedocs/gcc-7.1.0/gcc/Instrumentation-Options.html#Instrumentation-Options for information about the -fprofile-generate option.
#
#By default, GCC emits an error message if the feedback profiles do not match the source code. This error can be turned into a warning by using -Wcoverage-mismatch. Note this may result in poorly optimized code.
#
#If path is specified, GCC looks at the path to find the profile feedback data files. See -fprofile-dir. 
#LESLIE: This options use profiling, does argos use it?
# ALBERTO I don't see how this can be automated
#fprofile_use 	 "-" 	 c 	 (fno-profile-use, fprofile-use) 

#    Enable sampling-based feedback-directed optimizations, and the following optimizations which are generally profitable only with profile feedback available: -fbranch-probabilities, -fvpt, -funroll-loops, -fpeel-loops, -ftracer, -ftree-vectorize, -finline-functions, -fipa-cp, -fipa-cp-clone, -fpredictive-commoning, -funswitch-loops, -fgcse-after-reload, and -ftree-loop-distribute-patterns.
#
#    path is the name of a file containing AutoFDO profile information. If omitted, it defaults to fbdata.afdo in the current directory.
#
#    Producing an AutoFDO profile data file requires running your program with the perf utility on a supported GNU/Linux target system. For more information, see https://perf.wiki.kernel.org/.
#
#    E.g.
#
#    perf record -e br_inst_retired:near_taken -b -o perf.data \
#        -- your_program
#
#    Then use the create_gcov tool to convert the raw profile data to a format that can be used by GCC.  You must also supply the unstripped binary for your program to this tool. See https://github.com/google/autofdo.
#
#    E.g.
#
#    create_gcov --binary=your_program.unstripped --profile=perf.data \
#        --gcov=profile.afdo
#
#
#fauto_profile   "-"  c (CHECK VALUES)

############################################
#                                          #
#          floating point options          #
#                                          #
############################################

# Do not store floating-point variables in registers, and inhibit other options that might change whether a floating-point value is taken from a register or memory.
#This option prevents undesirable excess precision on machines such as the 68000 where the floating registers (of the 68881) keep more precision than a double is supposed to have. Similarly for the x86 architecture. For most programs, the excess precision does only good, but a few programs rely on the precise definition of IEEE floating point. Use -ffloat-store for such programs, after modifying them to store all pertinent intermediate computations into variables. LESLIE: check argos and acotsp
#ffloat_store 	 	 "-" 	 c 	 (fno-float-store, ffloat-store) 

# This option allows further control over excess precision on machines where floating-point registers have more precision than the IEEE float and double types and the processor does not support operations rounding to those types. By default, -fexcess-precision=fast is in effect; this means that operations are carried out in the precision of the registers and that it is unpredictable when rounding to the types specified in the source code takes place. When compiling C, if -fexcess-precision=standard is specified then excess precision follows the rules specified in ISO C99; in particular, both casts and assignments cause values to be rounded to their semantic types (whereas -ffloat-store only affects assignments). This option is enabled by default for C if a strict conformance option such as -std=c99 is used.
#-fexcess-precision=standard is not implemented for languages other than C, and has no effect if -funsafe-math-optimizations or -ffast-math is specified. On the x86, it also has no effect if -mfpmath=sse or -mfpmath=sse+387 is specified; in the former case, IEEE semantics apply without excess precision, and in the latter, rounding is unpredictable. LESLIE: removed because it does not seem a good idea
#fexcess_precision   "-"   c   (fno-excess-precision, fexcess-precision) |  funsafe_math_optimizations %in% c("funsafe-math-optimizations ") ||  ffast_math %in% c("ffast-math") 

# Sets the options -fno-math-errno, -funsafe-math-optimizations, -ffinite-math-only, -fno-rounding-math, -fno-signaling-nans and -fcx-limited-range. This option causes the preprocessor macro __FAST_MATH__ to be defined.
#This option is not turned on by any -O option besides -Ofast since it can result in incorrect output for programs that depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications. LESLIE: Removed because does not seem relevant
#ffast_math 	 	 "-" 	 c 	 (fno-fast-math, ffast-math) 

# Do not set errno after calling math functions that are executed with a single instruction, e.g., sqrt. A program that relies on IEEE exceptions for math error handling may want to use this flag for speed while maintaining IEEE arithmetic compatibility.
#This option is not turned on by any -O option since it can result in incorrect output for programs that depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications.
#The default is -fmath-errno.
#On Darwin systems, the math library never sets errno. There is therefore no reason for the compiler to consider the possibility that it might, and -fno-math-errno is the default. LESLIE: removed because it does not seem relevant
#fno_math_errno 	 "-" 	 c 	 (fno-math-errno, fmath-errno) 

# Allow optimizations for floating-point arithmetic that (a) assume that arguments and results are valid and (b) may violate IEEE or ANSI standards. When used at link time, it may include libraries or startup files that change the default FPU control word or other similar optimizations.
#This option is not turned on by any -O option since it can result in incorrect output for programs that depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications. Enables -fno-signed-zeros, -fno-trapping-math, -fassociative-math and -freciprocal-math.
#The default is -fno-unsafe-math-optimizations. LESLIE: removed because it does not seem relevant
#funsafe_math_optimizations 	 "-" 	 c 	 (fno-unsafe-math-optimizations, funsafe-math-optimizations) 

# Allow re-association of operands in series of floating-point operations. This violates the ISO C and C++ language standard by possibly changing computation result. NOTE: re-ordering may change the sign of zero as well as ignore NaNs and inhibit or create underflow or overflow (and thus cannot be used on code that relies on rounding behavior like (x + 2**52) - 2**52. May also reorder floating-point comparisons and thus may not be used when ordered comparisons are required. This option requires that both -fno-signed-zeros and -fno-trapping-math be in effect. Moreover, it doesn't make much sense with -frounding-math. For Fortran the option is automatically enabled when both -fno-signed-zeros and -fno-trapping-math are in effect. LESLIE: removed because does not make sense
# The default is -fno-associative-math.
#fassociative_math 	 		"-" 	 c  (fno-associative-math, fassociative-math) | !(funsafe_math_optimizations %in% c("funsafe-math-optimizations")) # the doc says does not make sense to use it with frounding !(frounding_math %in% c("frounding-math")) 

# Allow the reciprocal of a value to be used instead of dividing by the value if this enables optimizations. For example x / y can be replaced with x * (1/y), which is useful if (1/y) is subject to common subexpression elimination. Note that this loses precision and increases the number of flops operating on the value.
# The default is -fno-reciprocal-math. 
#freciprocal_math 	 "-" 	 c 	 (fno-reciprocal-math, freciprocal-math)

# Allow optimizations for floating-point arithmetic that assume that arguments and results are not NaNs or +-Infs.
#This option is not turned on by any -O option since it can result in incorrect output for programs that depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications.
#The default is -fno-finite-math-only. LESLIE: removed because it does not seem relevant
#ffinite_math_only 	 "-" 	 c 	 (fno-finite-math-only, ffinite-math-only) 

# Allow optimizations for floating-point arithmetic that ignore the signedness of zero. IEEE arithmetic specifies the behavior of distinct +0.0 and −0.0 values, which then prohibits simplification of expressions such as x+0.0 or 0.0*x (even with -ffinite-math-only). This option implies that the sign of a zero result isn't significant.
# The default is -fsigned-zeros. 
#fsigned_zeros 	 "-" 	 c 	 (fno-signed-zeros, fsigned-zeros) 

# Compile code assuming that floating-point operations cannot generate user-visible traps. These traps include division by zero, overflow, underflow, inexact result and invalid operation. This option requires that -fno-signaling-nans be in effect. Setting this option may allow faster code if one relies on “non-stop” IEEE arithmetic, for example.
#This option should never be turned on by any -O option since it can result in incorrect output for programs that depend on an exact implementation of IEEE or ISO rules/specifications for math functions.
#The default is -ftrapping-math. LESLIE: check this one!!!
#fno_trapping_math 	 "-" 	 c 	 (fno-trapping-math, ftrapping-math) |  fsignaling_nans %in% c("fsignaling-nans") 

# Disable transformations and optimizations that assume default floating-point rounding behavior. This is round-to-zero for all floating point to integer conversions, and round-to-nearest for all other arithmetic truncations. This option should be specified for programs that change the FP rounding mode dynamically, or that may be executed with a non-default rounding mode. This option disables constant folding of floating-point expressions at compile time (which may be affected by rounding mode) and arithmetic transformations that are unsafe in the presence of sign-dependent rounding modes.
#The default is -fno-rounding-math.
# This option is experimental and does not currently guarantee to disable all GCC optimizations that are affected by rounding mode. Future versions of GCC may provide finer control of this setting using C99's FENV_ACCESS pragma. This command-line option will be used to specify the default state for FENV_ACCESS. LESLIE: nor relevant
#frounding_math 	 "-" 	 c 	 (fno-rounding-math, frounding-math) 

#Compile code assuming that IEEE signaling NaNs may generate user-visible traps during floating-point operations. Setting this option disables optimizations that may change the number of exceptions visible with signaling NaNs. This option implies -ftrapping-math.
#This option causes the preprocessor macro __SUPPORT_SNAN__ to be defined.
#The default is -fno-signaling-nans.
#This option is experimental and does not currently guarantee to disable all GCC optimizations that affect signaling NaN behavior. 
#fsignaling_nans 	 "-" 	 c 	 (fno-signaling-nans, fsignaling-nans) | !(fno_trapping_math %in% c("fno_trapping_math"))

#Do not allow the built-in functions ceil, floor, round and trunc, and their float and long double variants, to generate code that raises the “inexact” floating-point exception for noninteger arguments. ISO C99 and C11 allow these functions to raise the “inexact” exception, but ISO/IEC TS 18661-1:2014, the C bindings to IEEE 754-2008, does not allow these functions to do so.
#
#The default is -ffp-int-builtin-inexact, allowing the exception to be raised. This option does nothing unless -ftrapping-math is in effect.
#
#Even if -fno-fp-int-builtin-inexact is used, if the functions generate a call to a library function then the “inexact” exception may be raised if the library implementation does not follow TS 18661. 
#ffp_int_builtin_inexact	"-"	c	(fno-fp-int-builtin-inexact, ffp-int-builtin-inexact)

# Treat floating-point constants as single precision instead of implicitly converting them to double-precision constants. LESLIE: not relevant
#fsingle_precision_constant 	 "-" 	 c 	 (fno-single-precision-constant, fsingle-precision-constant)	| (fno_trapping_math %in% (ftrapping-math))

# When enabled, this option states that a range reduction step is not needed when performing complex division. Also, there is no checking whether the result of a complex multiplication or division is NaN + I*NaN, with an attempt to rescue the situation in that case. The default is -fno-cx-limited-range, but is enabled by -ffast-math.
#This option controls the default setting of the ISO C99 CX_LIMITED_RANGE pragma. Nevertheless, the option applies to all languages. 
#fcx_limited_range 	 "-" 	 c 	 (fno-cx-limited-range, fcx-limited-range) | ffast_math %in% c("fno-fast-math")
#fcx_limited_range 	 "-" 	 c 	 (fno-cx-limited-range, fcx-limited-range) 

# Complex multiplication and division follow Fortran rules. Range reduction is done as part of complex division, but there is no checking whether the result of a complex multiplication or division is NaN + I*NaN, with an attempt to rescue the situation in that case.
#The default is -fno-cx-fortran-rules.
#fcx_fortran_rules 	 "-" 	 c 	 (fno-cx-fortran-rules, fcx-fortran-rules) 

############################################
#                                          #
#          to be used with caution         #
#                                          #
############################################

# The following options control optimizations that may improve performance, but are not enabled by any -O options. This section includes experimental options that may produce broken code. 

# After running a program compiled with -fprofile-arcs (see Instrumentation Options), you can compile it a second time using -fbranch-probabilities, to improve optimizations based on the number of times each branch was taken. When a program compiled with -fprofile-arcs exits, it saves arc execution counts to a file called sourcename.gcda for each source file. The information in this data file is very dependent on the structure of the generated code, so you must use the same source code and the same optimization options for both compilations.
#With -fbranch-probabilities, GCC puts a ‘REG_BR_PROB’ note on each ‘JUMP_INSN’ and ‘CALL_INSN’. These can be used to improve optimization. Currently, they are only used in one place: in reorg.c, instead of guessing which path a branch is most likely to take, the ‘REG_BR_PROB’ values are used to exactly determine which path is taken more often. 
#fbranch_probabilities 	 	"-" 	 c  (fno-branch-probabilities, fbranch-probabilities) #used when having a previously compiled program with -fprofile-arcs

# If combined with -fprofile-arcs, it adds code so that some data about values of expressions in the program is gathered.
# With -fbranch-probabilities, it reads back the data gathered from profiling values of expressions for usage in optimizations.
# Enabled with -fprofile-generate and -fprofile-use. 
# ALBERTO -fprofile-generate is not included here
#fprofile_values 	 "-" 	 c 	 (fno-profile-values, fprofile-values) 

#Function reordering based on profile instrumentation collects first time of execution of a function and orders these functions in ascending order. Enabled with -fprofile-use. 
#fprofile_reorder_functions  "-" c (fno-profile-reorder-functions, fprofile-reorder-functions)

# If combined with -fprofile-arcs, this option instructs the compiler to add code to gather information about values of expressions.
#With -fbranch-probabilities, it reads back the data gathered and actually performs the optimizations based on them. Currently the optimizations include specialization of division operations using the knowledge about the value of the denominator. 
#fvpt  "-"  c  (fno-vpt, fvpt)

# Attempt to avoid false dependencies in scheduled code by making use of registers left over after register allocation. This optimization most benefits processors with lots of registers. Depending on the debug information format adopted by the target, however, it can make debugging impossible, since variables no longer stay in a “home register”.
#Enabled by default with -funroll-loops and -fpeel-loops. 
#frename_registers 	 "-" 	 c 	 (fno-rename-registers, frename-registers) | funroll_loops %in% c("fno-unroll_loops") && funroll_all_loops %in% c("fno-unroll-all-loops") 
#&&  fpeel_loops %in% c("fno-peel-loops")

# Performs a target dependent pass over the instruction stream to schedule instructions of same type together because target machine can execute them more efficiently if they are adjacent to each other in the instruction flow. Enabled at levels -O2, -O3, -Os. 
#fschedule_fusion  "-"   c   (fno-schedule-fusion, fschedule-fusion)  

# Perform tail duplication to enlarge superblock size. This transformation simplifies the control flow of the function allowing other optimizations to do a better job. Enabled with -fprofile-use. 
# ftracer 	 "-" 	 c 	 (fno-tracer, ftracer) 

# Unroll loops whose number of iterations can be determined at compile time or upon entry to the loop. -funroll-loops implies -frerun-cse-after-loop, -fweb and -frename-registers. It also turns on complete loop peeling (i.e. complete removal of loops with a small constant number of iterations). This option makes code larger, and may or may not make it run faster. Enabled with -fprofile-use. 
funroll_loops 	 "-" 	 c 	 (fno-unroll-loops, funroll-loops) 

# Unroll all loops, even if their number of iterations is uncertain when the loop is entered. This usually makes programs run more slowly. -funroll-all-loops implies the same options as -funroll-loops. 
funroll_all_loops 	 "-" 	 c 	 (fno-unroll-all-loops, funroll-all-loops) 

# Split a loop into two if it contains a condition that’s always true for one side of the iteration space and false for the other.
#fsplit_loops	"-"	c	(fno-split-loops, fsplit-loops)

# Place each function or data item into its own section in the output file if the target supports arbitrary sections. The name of the function or the name of the data item determines the section's name in the output file.
# Use these options on systems where the linker can perform optimizations to improve locality of reference in the instruction space. Most systems using the ELF object format and SPARC processors running Solaris 2 have linkers with such optimizations. AIX may have these optimizations in the future.
# Only use these options when there are significant benefits from doing so. When you specify these options, the assembler and linker create larger object and executable files and are also slower. You cannot use gprof on all systems if you specify this option, and you may have problems with debugging if you specify both this option and -g. 
#fdata_sections 	 "-" 	 c 	 (fno-data-sections, fdata-sections) 
#ffunction_sections 	 "-" 	 c 	 (fno-function-sections, ffunction-sections)  

# Perform branch target register load optimization before prologue / epilogue threading. The use of target registers can typically be exposed only during reload, thus hoisting loads out of loops and doing inter-block scheduling needs a separate optimization pass. 
#fbranch_target_load_optimize 	"-" 	 c  (fno-branch-target-load-optimize, fbranch-target-load-optimize) 

# Perform branch target register load optimization after prologue / epilogue threading. 
#fbranch_target_load_optimize2 	"-" 	 c  (fno-branch-target-load-optimize2, fbranch-target-load-optimize2) 

# When performing branch target register load optimization, don't reuse branch target registers within any basic block. 
#fbtr_bb_exclusive 	 "-" 	 c 	 (fno-btr-bb-exclusive, fbtr-bb-exclusive) 

# Optimize the prologue of variadic argument functions with respect to usage of those arguments. 
#fstdarg_opt   "-"   c   (fno-stdarg-opt, fstdarg-opt)

# Try to reduce the number of symbolic address calculations by using shared “anchor” symbols to address nearby objects. This transformation can help to reduce the number of GOT entries and GOT accesses on some targets.
#For example, the implementation of the following function foo:
#          static int a, b, c;
#          int foo (void) { return a + b + c; }
# usually calculates the addresses of all three variables, but if you compile it with -fsection-anchors, it accesses the variables from a common anchor point instead. The effect is similar to the following pseudocode (which isn't valid C):
#         int foo (void){
#            register int *xr = &x;
#            return xr[&a - &x] + xr[&b - &x] + xr[&c - &x];
#          }
#Not all targets support this option. 
#fsection_anchors 	 "-" 	 c 	 (fno-section-anchors, fsection-anchors)  



############################################
#                                          #
#   end flags GCC 7.1 as per the webpage   #
#                                          #
############################################

# The following flags are not present in the webpage

# After register allocation and post-register allocation instruction splitting, perform a copy-propagation pass to try to reduce scheduling dependencies and occasionally eliminate the copy. Enabled at levels -O, -O2, -O3, -Os. 
#fcprop_registers 	 "-" 	 c 	 (fno-cprop-registers, fcprop-registers) 


# When enabled, this optimization propagates alignment of function parameters to support better vectorization and string operations. This flag is enabled by default at -O2 and -Os. It requires that -fipa-cp is enabled.
#fipa_cp_alignment   "-"   c   (fno-ipa-cp-alignment,fipa-cp-alignment) | fipa_cp %in% c("fipa-cp")

# Disable sharing of stack slots used for saving call-used hard registers living through a call. Each hard register gets a separate stack slot, and as a result function stack frames are larger. 
#fira_share_save_slots 	 "-" 	 c 	 (fno-ira-share-save-slots, fira-share-save-slots)  

#fmudflap 	 "-" 	 c 	 (fno-mudflap, fmudflap) #Check if this is relevant libmudflag
#fmudflapir 	 "-" 	 c 	 (fno-mudflapir, fmudflapir) 
#fmudflapth 	 "-" 	 c 	 (fno-mudflapth, fmudflapth)  

#foptimize_register_move 	 "-" 	 c 	 (fno-optimize-register-move, foptimize-register-move) #same as -fregmove 

# Optimize various standard C string functions (e.g. strlen, strchr or strcpy) and their _FORTIFY_SOURCE counterparts into faster alternatives. Same as -foptimize-register-move. Enabled at levels -O2, -O3. 
#fregmove 	 "-" 	 c 	 (fno-regmove, fregmove) 



# Attempt to also if-convert conditional jumps containing memory writes. This transformation can be unsafe for multi-threaded programs as it transforms conditional memory writes into unconditional memory writes. For example,
#          for (i = 0; i < N; i++)
#            if (cond)
#              A[i] = expr;
# is transformed to
#
#          for (i = 0; i < N; i++)
#            A[i] = cond ? expr : A[i];
# potentially producing data races. 
#ftree_loop_if_convert_stores    "-"   c   (fno-tree-loop-if-convert-stores, ftree-loop-if-convert-stores)

#This option tells the loop optimizer to assume that loop indices do not overflow, and that loops with nontrivial exit condition are not infinite. This enables a wider range of loop optimizations even if the loop optimizer itself cannot prove that these assumptions are valid. If you use -Wunsafe-loop-optimizations, the compiler warns you if it finds this kind of loop. 
#funsafe_loop_optimizations 	 "-" 	 c 	 (fno-unsafe-loop-optimizations, funsafe-loop-optimizations)

# Alter the cost model used for vectorization of loops marked with the OpenMP or Cilk Plus simd directive. The model argument should be one of ‘unlimited’, ‘dynamic’, ‘cheap’. All values of model have the same meaning as described in -fvect-cost-model and by default a cost model defined with -fvect-cost-model is used.
#fsimd_cost_model    "-fsimd-cost-model="    c   (unlimited, dynamic, cheap)


############################################
#                                          #
#           numerical parameters           #
#                                          #
############################################


# When branch is predicted to be taken with probability lower than this
#   threshold (in percent), then it is considered well predictable.

# Maximal estimated outcome of branch considered predictable.
predictable_branch_outcome	"--param predictable-branch-outcome="	i	(0, 50)

# The minimal estimated speedup allowing inliner to ignore inline-insns-single and inline-insns-auto.
##RANGE def 8
inline_min_speedup	"--param inline-min-speedup="	i	(0, 32)

# The single function inlining limit. This is the maximum size
#   of a function counted in internal gcc instructions (not in
#   real machine instructions) that is eligible for inlining
#   by the tree inliner.
#   The default value is 450.
#   Only functions marked inline (or methods defined in the class
#   definition for C++) are affected by this.
#   There are more restrictions to inlining: If inlined functions
#   call other functions, the already inlined instructions are
#   counted and once the recursive inline limit (see
#   "max-inline-insns" parameter) is exceeded, the acceptable size
#   gets decreased. 

# The maximum number of instructions in a single function eligible for inlining.
##RANGE def 450
max_inline_insns_single	"--param max-inline-insns-single="	i	(0, 1800)

# The single function inlining limit for functions that are
#   inlined by virtue of -finline-functions (-O3).
#   This limit should be chosen to be below or equal to the limit
#   that is applied to functions marked inlined (or defined in the
#   class declaration in C++) given by the "max-inline-insns-single"
#   parameter.
#   The default value is 40. 
# The maximum number of instructions when automatically inlining.
##RANGE def 40
max_inline_insns_auto	"--param max-inline-insns-auto="	i	(0, 160)

# The maximum number of instructions inline function can grow to via recursive inlining.
##RANGE def 450
max_inline_insns_recursive	"--param max-inline-insns-recursive="	i	(0, 1800)

# The maximum number of instructions non-inline function can grow to via recursive inlining.
##RANGE def 450
max_inline_insns_recursive_auto	"--param max-inline-insns-recursive-auto="	i	(0, 1800)

# The maximum depth of recursive inlining for inline functions.
##RANGE def 8
max_inline_recursive_depth	"--param max-inline-recursive-depth="	i	(0, 32)

# The maximum depth of recursive inlining for non-inline functions.
##RANGE def 8
max_inline_recursive_depth_auto	"--param max-inline-recursive-depth-auto="	i	(0, 32)

# Inline recursively only when the probability of call being executed exceeds the parameter.
##RANGE def 10 (??? percent?)
min_inline_recursive_probability	"--param min-inline-recursive-probability="	i	(0, 40)

# Limit of iterations of early inliner.  This basically bounds number of
#   nested indirect calls early inliner can resolve.  Deeper chains are still
#   handled by late inlining.  

# The maximum number of nested indirect inlining performed by early inliner.
##RANGE def 1
max_early_inliner_iterations	"--param max-early-inliner-iterations="	i	(0, 4)

# Limit on probability of entry BB. 
# Probability that COMDAT function will be shared with different compilation unit.
##RANGE def 20
comdat_sharing_probability	"--param comdat-sharing-probability="	i	(0, 80)

# Limit on probability of entry BB.  
# Maximum probability of the entry BB of split region (in percent relative to entry BB of the function) to make partial inlining happen.
##RANGE def 70
partial_inlining_entry_probability	"--param partial-inlining-entry-probability="	i	(0, 280)

# Limit the number of expansions created by the variable expansion
#   optimization to avoid register pressure. 
# If -fvariable-expansion-in-unroller is used, the maximum number of times that an individual variable will be expanded during loop unrolling.
##RANGE def 1
max_variable_expansions_in_unroller	"--param max-variable-expansions-in-unroller="	i	(0, 4)

# Limit loop autovectorization to loops with large enough iteration count. 
# If -ftree-vectorize is used, the minimal loop bound of a loop to be considered for vectorization.
##RANGE def 1
min_vect_loop_bound	"--param min-vect-loop-bound="	i	(1, 4)

# The maximum number of instructions to consider when looking for an
#   instruction to fill a delay slot.  If more than this arbitrary
#   number of instructions is searched, the time savings from filling
#   the delay slot will be minimal so stop searching.  Increasing
#   values mean more aggressive optimization, making the compile time
#   increase with probably small improvement in executable run time.  
# The maximum number of instructions to consider to fill a delay slot.
##RANGE def 100
max_delay_slot_insn_search	"--param max-delay-slot-insn-search="	i	(0, 400)

# When trying to fill delay slots, the maximum number of instructions
#   to consider when searching for a block with valid live register
#   information.  Increasing this arbitrarily chosen value means more
#   aggressive optimization, increasing the compile time.  This
#   parameter should be removed when the delay slot code is rewritten
#   to maintain the control-flow graph.  */
# The maximum number of instructions to consider to find accurate live register information.
##RANGE def 333
max_delay_slot_live_search	"--param max-delay-slot-live-search="	i	(0, 1333)

# This parameter limits the number of branch elements that the
#   scheduler will track anti-dependencies through without resetting
#   the tracking mechanism.  Large functions with few calls or barriers
#   can generate lists containing many 1000's of dependencies.  Generally
#   the compiler either uses all available memory, or runs for far too long.  */
# The maximum length of scheduling's pending operations list.
##RANGE def 32
max_pending_list_length	"--param max-pending-list-length="	i	(0, 128)

# This parameter limits the number of backtracking attempts when using the
#   haifa scheduler for modulo scheduling.  */
##RANGE def 40
max_modulo_backtrack_attempts	"--param max-modulo-backtrack-attempts="	i	(0, 160)

# The size of function body to be considered large.
##RANGE def 2700
large_function_insns	"--param large-function-insns="	i	(0, 10800)

# Maximal growth due to inlining of large function (in percent).
##RANGE def 100
large_function_growth	"--param large-function-growth="	i	(0, 400)

# The size of translation unit to be considered large.
##RANGE def 10000
large_unit_insns	"--param large-unit-insns="	i	(0, 40000)

# How much can given compilation unit grow because of the inlining (in percent).
##RANGE def 20
inline_unit_growth	"--param inline-unit-growth="	i	(0, 80)

# How much can given compilation unit grow because of the interprocedural constant propagation (in percent).
##RANGE def 10
ipcp_unit_growth	"--param ipcp-unit-growth="	i	(0, 40)

# Maximal estimated growth of function body caused by early inlining of single call.
##RANGE def 14
early_inlining_insns	"--param early-inlining-insns="	i	(0, 56)

# The size of stack frame to be considered large.
##RANGE def 256
large_stack_frame	"--param large-stack-frame="	i	(0, 1024)

# Maximal stack frame growth due to inlining (in percent).
##RANGE def 1000
large_stack_frame_growth	"--param large-stack-frame-growth="	i	(0, 4000)

# The GCSE optimization will be disabled if it would require
#   significantly more memory than this value.  
# The maximum amount of memory to be allocated by GCSE.
##RANGE def 128 * 1024 * 1024
max_gcse_memory	"--param max-gcse-memory="	i	(0, 536870912)

# The GCSE optimization of an expression will avoided if the ratio of
#   insertions to deletions is greater than this value.  
##RANGE def 20
max_gcse_insertion_ratio	"--param max-gcse-insertion-ratio="	i	(0, 80)

# This is the threshold ratio when to perform partial redundancy
#   elimination after reload. We perform partial redundancy elimination
#   when the following holds:
#   (Redundant load execution count)
#   ------------------------------- >= GCSE_AFTER_RELOAD_PARTIAL_FRACTION
#   (Added loads execution count)					  
# The threshold ratio for performing partial redundancy elimination after reload.
##RANGE def 3
gcse_after_reload_partial_fraction	"--param gcse-after-reload-partial-fraction="	i	(0, 12)

# This is the threshold ratio of the critical edges execution count compared to
#   the redundant loads execution count that permits performing the load
#   redundancy elimination in gcse after reload.  
# The threshold ratio of critical edges execution count that permit performing redundancy elimination after reload.
##RANGE def 10
gcse_after_reload_critical_fraction	"--param gcse-after-reload-critical-fraction="	i	(0, 40)

# GCSE will use GCSE_COST_DISTANCE_RATION as a scaling factor
#   to calculate maximum distance for which an expression is allowed to move
#   from its rtx_cost.  
##RANGE def 10
gcse_cost_distance_ratio	"--param gcse-cost-distance-ratio="	i	(0, 40)

# GCSE won't restrict distance for which an expression with rtx_cost greater
#   than COSTS_N_INSN(GCSE_UNRESTRICTED_COST) is allowed to move. 
# Cost at which GCSE optimizations will not constraint the distance an expression can travel.
##RANGE def 3
gcse_unrestricted_cost	"--param gcse-unrestricted-cost="	i	(0, 12)

# How deep from a given basic block the dominator tree should be searched
#   for expressions to hoist to the block.  The value of 0 will avoid limiting
#   the search.  
# Maximum depth of search in the dominator tree for expressions to hoist.
##RANGE def 30
max_hoist_depth	"--param max-hoist-depth="	i	(0, 120)

# When synthesizing expnonentiation by a real constant operations using square
#   roots, this controls how deep sqrt chains we are willing to generate.
# Maximum depth of sqrt chains to use when synthesizing exponentiation by a real constant.
# def 5
max_pow_sqrt_depth	"--param max-pow-sqrt-depth="	i	(1, 32)

# This parameter limits the number of insns in a loop that will be unrolled,
#   and by how much the loop is unrolled.
#
#   This limit should be at most half of the peeling limits:  loop unroller
#   decides to not unroll loops that iterate fewer than 2*number of allowed
#   unrollings and thus we would have loops that are neither peeled or unrolled
#   otherwise.  *
# The maximum number of instructions to consider to unroll in a loop.
##RANGE def 200
max_unrolled_insns	"--param max-unrolled-insns="	i	(0, 800)

# This parameter limits how many times the loop is unrolled depending
#   on number of insns really executed in each iteration. 
# The maximum number of instructions to consider to unroll in a loop on average.
##RANGE def 80
max_average_unrolled_insns	"--param max-average-unrolled-insns="	i	(0, 320)

# The maximum number of unrollings of a single loop.  
##RANGE def 8
max_unroll_times	"--param max-unroll-times="	i	(0, 32)

#The maximum number of insns of a peeled loop. 
##RANGE def 100
max_peeled_insns	"--param max-peeled-insns="	i	(0, 400)

# The maximum number of peelings of a single loop. 
##RANGE def 16
max_peel_times	"--param max-peel-times="	i	(0, 64)

# The maximum number of peelings of a single loop that is peeled completely. 
##RANGE def 32
max_peel_branches	"--param max-peel-branches="	i	(0, 128)

# The maximum number of insns of a peeled loop. 
##RANGE def 200
max_completely_peeled_insns	"--param max-completely-peeled-insns="	i	(0, 800)

# The maximum number of peelings of a single loop that is peeled completely.
##RANGE def 16
max_completely_peeled_times	"--param max-completely-peel-times="	i	(0, 64)

# The maximum number of insns of a peeled loop that rolls only once. 
##RANGE def 400
max_once_peeled_insns	"--param max-once-peeled-insns="	i	(0, 1600)

# The maximum depth of a loop nest we completely peel. 
##RANGE def 8
max_completely_peel_loop_nest_depth	"--param max-completely-peel-loop-nest-depth="	i	(0, 32)

# The maximum number of insns of an unswitched loop. 
##RANGE def 50
max_unswitch_insns	"--param max-unswitch-insns="	i	(0, 200)

# The maximum level of recursion in unswitch_single_loop. 
##RANGE def 3
max_unswitch_level	"--param max-unswitch-level="	i	(0, 12)

# The maximum number of insns in loop header duplicated by he copy loop
#   headers pass.  
##RANGE def 20
max_loop_header_insns	"--param max-loop-header-insns="	i	(0, 80)

# The maximum number of iterations of a loop the brute force algorithm
#   for analysis of # of iterations of the loop tries to evaluate.  */
# Bound on the number of iterations the brute force # of iterations analysis algorithm evaluates.
##RANGE def 1000
max_iterations_to_track	"--param max-iterations-to-track="	i	(0, 4000)

# A cutoff to avoid costly computations of the number of iterations in
#   the doloop transformation. 
# Bound on the cost of an expression to compute the number of iterations.
##RANGE def 10
max_iterations_computation_cost	"--param max-iterations-computation-cost="	i	(0, 40)

# This parameter is used to tune SMS MAX II calculations. 
# A factor for tuning the upper bound that swing modulo scheduler uses for scheduling a loop.
##RANGE def 100
sms_max_ii_factor	"--param sms-max-ii-factor="	i	(0, 400)

# The minimum value of stage count that swing modulo scheduler will generate.
##RANGE def 2
sms_min_sc	"--param sms-min-sc="	i	(1, 8)

# The number of cycles the swing modulo scheduler considers when checking conflicts using DFA.
##RANGE def 0
sms_dfa_history	"--param sms-dfa-history="	i	(0, 4)

# A threshold on the average loop count considered by the swing modulo scheduler.
##RANGE def 0
sms_loop_average_count_threshold	"--param sms-loop-average-count-threshold="	i	(0, 4)

# A basic block profile count is considered hot if it contributes to
# the given permillage of the entire profiled execution.
# def 999
hot_bb_count_ws_permille	"--param hot-bb-count-ws-permille="	i	(0, 1000)

# Select fraction of the maximal frequency of executions of basic block in function given basic block needs to have to be considered hot.
##RANGE def 1000
hot_bb_frequency_fraction	"--param hot-bb-frequency-fraction="	i	(0, 4000)

# The minimum fraction of profile runs a given basic block execution count must be not to be considered unlikely.
# def 20
unlikely_bb_count_fraction	"--param unlikely-bb-count-fraction="	i	(1, 10000)

# Select fraction of the maximal frequency of executions of basic block in function given basic block get alignment.
##RANGE def 100
align_threshold	"--param align-threshold="	i	(1, 400)

# Loops iterating at least selected number of iterations will get loop alignment.
##RANGE def 4
align_loop_iterations	"--param align-loop-iterations="	i	(0, 16)

# For guessed profiles, the loops having unknown number of iterations
#   are predicted to iterate relatively few (10) times at average.
#   For functions containing one loop with large known number of iterations
#   and other loops having unbounded loops we would end up predicting all
#   the other loops cold that is not usually the case.  So we need to artificially
#   flatten the profile.
#
#   We need to cut the maximal predicted iterations to large enough iterations
#   so the loop appears important, but safely within maximum hotness
#   range.  
#The maximum number of loop iterations we predict statically.
##RANGE def 100
max_predicted_iterations	"--param max-predicted-iterations="	i	(0, 400)

# This parameter controls the probability of builtin_expect. The default
#   value is 90%. This empirical value is obtained through the weighted
#   probability of FDO counters (with the FDO count value as the weight)
#   in some real world programs:
#   (1) Google performance test benchmarks: the probability is 0.9081.
#   (2) Linux 3.3 kernel running Google search workload: the probability
#   is 0.8717.  */
# Set the estimated probability in percentage for builtin expect. The default value is 90% probability.
# def 90
builtin_expect_probability	"--param builtin-expect-probability="	i	(0, 100)

# The percentage of function, weighted by execution frequency, that must be covered by trace formation. Used when profile feedback is available.
# def 95
tracer_dynamic_coverage_feedback	"--param tracer-dynamic-coverage-feedback="	i	(0, 100)

# The percentage of function, weighted by execution frequency, that must be covered by trace formation. Used when profile feedback is not available.
# def 75
tracer_dynamic_coverage	"--param tracer-dynamic-coverage="	i	(0, 100)

# Maximal code growth caused by tail duplication (in percent).
##RANGE is (0, 0), def 100 - but it's a percentage, so I set the range to (0, 100)
tracer_max_code_growth	"--param tracer-max-code-growth="	i	(0, 100)

# Stop reverse growth if the reverse probability of best edge is less than this threshold (in percent).
# def 10
tracer_min_branch_ratio	"--param tracer-min-branch-ratio="	i	(0, 100)

# Stop forward growth if the probability of best edge is less than this threshold (in percent). Used when profile feedback is available.
# def 80
tracer_min_branch_probability_feedback	"--param tracer-min-branch-probability-feedback="	i	(0, 100)

# Stop forward growth if the probability of best edge is less than this threshold (in percent). Used when profile feedback is not available.
# def 50
tracer_min_branch_probability	"--param tracer-min-branch-probability="	i	(0, 100)

# The maximum number of incoming edges to consider for crossjumping.
##RANGE def 100
max_crossjump_edges	"--param max-crossjump-edges="	i	(0, 100)

# The minimum number of matching instructions to consider for crossjumping. 
##RANGE def 5
#min_crossjump_insns	"--param min-crossjump-insns="	i	(1, 20)

# The maximum number expansion factor when copying basic blocks. 
##RANGE def 8
max_grow_copy_bb_insns	"--param max-grow-copy-bb-insns="	i	(0, 32)

# The maximum number of insns to duplicate when unfactoring computed gotos.
##RANGE def 8
max_goto_duplication_insns	"--param max-goto-duplication-insns="	i	(0, 32)

# The maximum length of path considered in cse.  
##RANGE def 10
max_cse_path_length	"--param max-cse-path-length="	i	(1, 40)

# The maximum instructions CSE process before flushing.
##RANGE def 1000
max_cse_insns	"--param max-cse-insns="	i	(0, 4000)

# The cost of expression in loop invariant motion that is considered
#   expensive. 
# The minimum cost of an expensive expression in the loop invariant motion.
##RANGE def 20
lim_expensive	"--param lim-expensive="	i	(0, 80)

# Bound on number of candidates for induction variables below that
#   all candidates are considered for each use in induction variable
#   optimizations.
##RANGE def 40
iv_consider_all_candidates_bound	"--param iv-consider-all-candidates-bound="	i	(0, 160)

# The induction variable optimizations give up on loops that contain more
#   induction variable uses.
##RANGE def 250
iv_max_considered_uses	"--param iv-max-considered-uses="	i	(0, 1000)

# If there are at most this number of ivs in the set, try removing unnecessary
#   ivs from the set always.
##RANGE def 10
iv_always_prune_cand_set_bound	"--param iv-always-prune-cand-set-bound="	i	(0, 40)

# Average number of iterations of a loop.
##RANGE def 10
avg_loop_niter	"--param avg-loop-niter="	i	(1, 40)

# Maximum size (in bytes) of objects tracked bytewise by dead store elimination.
##RANGE def 256
dse_max_object_size	"--param dse-max-object-size="	i	(0, 1024)

# Bound on size of expressions used in the scalar evolutions analyzer.
##RANGE def 100
scev_max_expr_size	"--param scev-max-expr-size="	i	(0, 400)

# Bound on the complexity of the expressions in the scalar evolutions analyzer.
##RANGE def 10
scev_max_expr_complexity	"--param scev-max-expr-complexity="	i	(0, 40)

# Maximum number of arguments in a PHI supported by TREE if-conversion unless the loop is marked with simd pragma.
##RANGE def 4
max_tree_if_conversion_phi_args	"--param max-tree-if-conversion-phi-args="	i	(2, 8)

# Bound on number of runtime checks inserted by the vectorizer's loop versioning for alignment check.
##RANGE def 6
vect_max_version_for_alignment_checks	"--param vect-max-version-for-alignment-checks="	i	(0, 24)

# Bound on number of runtime checks inserted by the vectorizer's loop versioning for alias check.
##RANGE def 10
vect_max_version_for_alias_checks	"--param vect-max-version-for-alias-checks="	i	(0, 40)

# Maximum number of loop peels to enhance alignment of data references in a loop.
# def -1
vect_max_peeling_for_alignment	"--param vect-max-peeling-for-alignment="	i	(-1, 64)

# The maximum memory locations recorded by cselib.
##RANGE def 500
max_cselib_memory_locations	"--param max-cselib-memory-locations="	i	(0, 2000)

##ALBERTO: I don't know if this is going to be useful
#ifdef ENABLE_GC_ALWAYS_COLLECT
# define GGC_MIN_EXPAND_DEFAULT 0
# define GGC_MIN_HEAPSIZE_DEFAULT 0
#else
# define GGC_MIN_EXPAND_DEFAULT 30
# define GGC_MIN_HEAPSIZE_DEFAULT 4096
#endif

# Minimum heap expansion to trigger garbage collection, as a percentage of the total size of the heap.
##RANGE def GGC_MIN_EXPAND_DEFAULT
ggc_min_expand	"--param ggc-min-expand="	i	(0, 120)

# Minimum heap size before we start collecting garbage, in kilobytes.
##RANGE def GGC_MIN_HEAPSIZE_DEFAULT
ggc_min_heapsize	"--param ggc-min-heapsize="	i	(0, 16384)

#undef GGC_MIN_EXPAND_DEFAULT
#undef GGC_MIN_HEAPSIZE_DEFAULT

# The maximum number of instructions to search backward when looking for equivalent reload.
##RANGE def 100
max_reload_search_insns	"--param max-reload-search-insns="	i	(0, 400)

# Target block's relative execution frequency (as a percentage) required to sink a statement.
# def 75
sink_frequency_threshold	"--param sink-frequency-threshold="	i	(0, 100)

# The maximum number of blocks in a region to be considered for interblock scheduling.
##RANGE def 10
max_sched_region_blocks	"--param max-sched-region-blocks="	i	(0, 40)

# The maximum number of insns in a region to be considered for interblock scheduling.
##RANGE def 100
max_sched_region_insns	"--param max-sched-region-insns="	i	(0, 400)

# The maximum number of blocks in a region to be considered for interblock scheduling.
##RANGE def 15
max_pipeline_region_blocks	"--param max-pipeline-region-blocks="	i	(0, 60)

# The maximum number of insns in a region to be considered for interblock scheduling.
##RANGE def 200
max_pipeline_region_insns	"--param max-pipeline-region-insns="	i	(0, 800)

# The minimum probability of reaching a source block for interblock speculative scheduling.
##RANGE def 40
min_spec_prob	"--param min-spec-prob="	i	(0, 160)

# The maximum number of iterations through CFG to extend regions.
##RANGE def 0
max_sched_extend_regions_iters	"--param max-sched-extend-regions-iters="	i	(0, 4)

# The maximum conflict delay for an insn to be considered for speculative motion.
# def 3
max_sched_insn_conflict_delay	"--param max-sched-insn-conflict-delay="	i	(1, 10)

# The minimal probability of speculation success (in percents), so that speculative insn will be scheduled.
# def 40
sched_spec_prob_cutoff	"--param sched-spec-prob-cutoff="	i	(0, 100)

# The minimum probability an edge must have for the scheduler to save its state across it.
# def 10
sched_state_edge_prob_cutoff	"--param sched-state-edge-prob-cutoff="	i	(0, 100)

# The maximum size of the lookahead window of selective scheduling.
##RANGE def 50
selsched_max_lookahead	"--param selsched-max-lookahead="	i	(0, 200)

# Maximum number of times that an insn could be scheduled.
##RANGE def 2
selsched_max_sched_times	"--param selsched-max-sched-times="	i	(1, 8)

# Maximum number of instructions in the ready list that are considered eligible for renaming.
##RANGE def 2
selsched_insns_to_rename	"--param selsched-insns-to-rename="	i	(0, 8)

# Minimal distance between possibly conflicting store and load.
##RANGE def 1
sched_mem_true_dep_cost	"--param sched-mem-true-dep-cost="	i	(0, 4)

# Hardware autoprefetcher scheduler model control flag.  Number of lookahead cycles the model looks into; at '0' only enable instruction sorting heuristic.  Disabled by default.
##RANGE def -1
#LESLIE: when compiling we get an error with the negative numbers so i will deactivate it 
#sched_autopref_queue_depth	"--param sched-autopref-queue-depth="	i	(-4, 0)

# The maximum number of RTL nodes that can be recorded as combiner's last value.
##RANGE def 10000
max_last_value_rtl	"--param max-last-value-rtl="	i	(0, 40000)

# The maximum number of insns combine tries to combine.
# def 4
max_combine_insns	"--param max-combine-insns="	i	(2, 4)

# INTEGER_CST nodes are shared for values [{-1,0} .. N) for
#   {signed,unsigned} integral types.  This determines N.
#   Experimentation shows 251 to be a good value that generates the
#   least amount of garbage for allocating the TREE_VEC storage.

# The upper bound for sharing integer constants.
##RANGE def 251
integer_share_limit	"--param integer-share-limit="	i	(0, 1004)

# The lower bound for a buffer to be considered for stack smashing protection.
##RANGE def 8
ssp_buffer_size	"--param ssp-buffer-size="	i	(1, 32)

# The minimum size of variables taking part in stack slot sharing 
##RANGE def 32
min_size_for_stack_sharing	"--param min-size-for-stack-sharing="	i	(0, 128)

# When we thread through a block we have to make copies of the
#   statements within the block.  Clearly for large blocks the code
#   duplication is bad.
#
#   PARAM_MAX_JUMP_THREAD_DUPLICATION_STMTS specifies the maximum number
#   of statements and PHI nodes allowed in a block which is going to
#   be duplicated for thread jumping purposes.
#
#   Some simple analysis showed that more than 99% of the jump
#   threading opportunities are for blocks with less than 15
#   statements.  So we can get the benefits of jump threading
#   without excessive code bloat for pathological cases with the
#   throttle set at 15 statements. 

# Maximum number of statements allowed in a block that needs to be duplicated when threading jumps.
##RANGE def 15
max_jump_thread_duplication_stmts	"--param max-jump-thread-duplication-stmts="	i	(0, 60)

# This is the maximum number of fields a variable may have before the pointer analysis machinery
#   will stop trying to treat it in a field-sensitive manner.
#   There are programs out there with thousands of fields per structure, and handling them
#   field-sensitively is not worth the cost. 

# Maximum number of fields in a structure before pointer analysis treats the structure as a single variable.
##RANGE def 0
max_fields_for_field_sensitive	"--param max-fields-for-field-sensitive="	i	(0, 4)

# The maximum number of instructions ready to be issued to be considered by the scheduler during the first scheduling pass.
##RANGE def 100
max_sched_ready_insns	"--param max-sched-ready-insns="	i	(0, 400)

# This is the maximum number of active local stores RTL DSE will consider. 
##RANGE def 5000
max_dse_active_local_stores	"--param max-dse-active-local-stores="	i	(0, 20000)

# Prefetching and cache-optimizations related parameters.  Default values are
#   usually set by machine description. 

# The number of insns executed before prefetch is completed.
##RANGE def 200
prefetch_latency	"--param prefetch-latency="	i	(0, 800)

# The number of prefetches that can run at the same time.
##RANGE def 3
simultaneous_prefetches	"--param simultaneous-prefetches="	i	(0, 12)

# The size of L1 cache in kB. 
##RANGE def 64
l1_cache_size	"--param l1-cache-size="	i	(0, 256)

# The size of L1 cache line in bytes. 
##RANGE def 32
l1_cache_line_size	"--param l1-cache-line-size="	i	(0, 128)

# The size of L2 cache in kB. 
##RANGE def 512
l2_cache_size	"--param l2-cache-size="	i	(0, 2048)

# Whether we should use canonical types rather than deep "structural"
#   type checking.  Setting this value to 1 (the default) improves
#   compilation performance in the C++ and Objective-C++ front end;
#   this value should only be set to zero to work around bugs in the
#   canonical type system by disabling it.

# Whether to use canonical types.
# def 1
use_canonical_types	"--param use-canonical-types="	i	(0, 1)

# Maximum length of partial antic set when performing tree pre optimization.
##RANGE def 100
max_partial_antic_length	"--param max-partial-antic-length="	i	(0, 400)

# The following is used as a stop-gap limit for cases where really huge
#   SCCs blow up memory and compile-time use too much.  If we hit this limit,
#   SCCVN and such FRE and PRE will be not done at all for the current
#   function. 

# Maximum size of a SCC before SCCVN stops processing a function.
##RANGE def 100
sccvn_max_scc_size	"--param sccvn-max-scc-size="	i	(10, 400)

# The following is used as a stop-gap limit for cases where really huge
#   functions blow up compile-time use too much.  It limits the number of
#   alias-queries we do for finding common subexpressions for memory loads and
#   stores.  The number of alias-queries is otherwise limited by the number of
#   stores on paths to function entry. 

# Maximum number of disambiguations to perform per memory access.
##RANGE def 1000
sccvn_max_alias_queries_per_access	"--param sccvn-max-alias-queries-per-access="	i	(0, 4000)

# Max loops number for regional RA.
##RANGE def 100
ira_max_loops_num	"--param ira-max-loops-num="	i	(0, 400)

# Max size of conflict table in MB.
##RANGE def 1000
ira_max_conflict_table_size	"--param ira-max-conflict-table-size="	i	(0, 4000)

# The number of registers in each class kept unused by loop invariant motion.
##RANGE def 2
ira_loop_reserved_regs	"--param ira-loop-reserved-regs="	i	(0, 8)

# The max number of reload pseudos which are considered during spilling a non-reload pseudo
##RANGE def 500
lra_max_considered_reload_pseudos	"--param lra-max-considered-reload-pseudos="	i	(0, 2000)

# Minimal fall-through edge probability in percentage used to add BB to inheritance EBB in LRA.
# def 40
lra_inheritance_ebb_probability_cutoff	"--param lra-inheritance-ebb-probability-cutoff="	i	(0, 100)

# Switch initialization conversion will refuse to create arrays that are
#   bigger than this parameter times the number of switch branches. 

# The maximum ratio between array size and switch branches for a switch conversion to take place.
##RANGE def 8
switch_conversion_max_branch_ratio	"--param switch-conversion-max-branch-ratio="	i	(1, 32)

# Size of tiles when doing loop blocking. 
##RANGE def 51
loop_block_tile_size	"--param loop-block-tile-size="	i	(0, 204)

# Maximal number of parameters that we allow in a SCoP. 
##RANGE def 7
graphite_max_nb_scop_params	"--param graphite-max-nb-scop-params="	i	(0, 28)

# Maximal number of basic blocks in the functions analyzed by Graphite. 
##RANGE def 100
graphite_max_bbs_per_function	"--param graphite-max-bbs-per-function="	i	(0, 400)

# Maximal number of array references in a scop. 
##RANGE def 100
graphite_max_arrays_per_scop	"--param graphite-max-arrays-per-scop="	i	(0, 400)

# Maximal number of basic blocks in the functions analyzed by Graphite.
##RANGE def 2
graphite_min_loops_per_function	"--param graphite-min-loops-per-function="	i	(0, 8)

# maximum number of isl operations, 0 means unlimited
##RANGE def 350000
max_isl_operations	"--param max-isl-operations="	i	(0, 1400000)

# Avoid data dependence analysis on very large loops. 
# Maximum number of datarefs in loop for building loop data dependencies.
##RANGE def 1000
loop_max_datarefs_for_datadeps	"--param loop-max-datarefs-for-datadeps="	i	(0, 4000)

# Avoid doing loop invariant motion on very large loops. 
##RANGE def 10000
loop_invariant_max_bbs_in_loop	"--param loop-invariant-max-bbs-in-loop="	i	(0, 40000)

# When the parameter is 1, use the internal function id
#   to look up for profile data. Otherwise, use a more stable
#   external id based on assembler name and source location.
# use internal function id in profile lookup
# def 0
profile_func_internal_id	"--param profile-func-internal-id="	i	(0, 1)

# When the parameter is 1, track the most frequent N target
#   addresses in indirect-call profile. This disables
#   indirect_call_profiler_v2 which tracks single target. 

# track topn target addresses in indirect-call profile.
# def 0
indir_call_topn_profile	"--param indir-call-topn-profile="	i	(0, 1)

# Avoid SLP vectorization of large basic blocks. 
##RANGE def 1000
slp_max_insns_in_bb	"--param slp-max-insns-in-bb="	i	(0, 4000)

# Min. ratio of insns to prefetches to enable prefetching for a loop with an unknown trip count.
##RANGE def 9
min_insn_to_prefetch_ratio	"--param min-insn-to-prefetch-ratio="	i	(0, 36)

# Min. ratio of insns to mem ops to enable prefetching in a loop.
##RANGE def 3
#prefetch_min_insn_to_mem_ratio	"--param prefetch-min-insn-to-mem-ratio="	i	(0, 0)

# Set maximum hash table size for var tracking.  
# Max. size of var tracking hash tables.
##RANGE def 50000000
max_vartrack_size	"--param max-vartrack-size="	i	(0, 200000000)

# Set maximum recursion depth for var tracking expression expansion
# and resolution. 
# Max. recursion depth for expanding var tracking expressions.
##RANGE def 12
max_vartrack_expr_depth	"--param max-vartrack-expr-depth="	i	(0, 48)

# Set maximum length of value location list for which var tracking
#   should add reverse operations.
# Max. size of loc list for which reverse ops should be added.
##RANGE def 50
max_vartrack_reverse_op_size	"--param max-vartrack-reverse-op-size="	i	(0, 200)

# Set minimum insn uid for non-debug insns. 
# The minimum UID to be used for a nondebug insn.
##RANGE def 0
min_nondebug_insn_uid	"--param min-nondebug-insn-uid="	i	(0, 4)

# Maximum allowed growth of size of new parameters ipa-sra replaces a pointer to an aggregate with.
##RANGE def 2
ipa_sra_ptr_growth_factor	"--param ipa-sra-ptr-growth-factor="	i	(0, 8)

# Size in bytes after which thread-local aggregates should be instrumented with the logging functions instead of save/restore pairs.
##RANGE def 9
tm_max_aggregate_size	"--param tm-max-aggregate-size="	i	(0, 36)

# Maximum size, in storage units, of an aggregate which should be considered for scalarization when compiling for speed.
##RANGE def 0
sra_max_scalarization_size_Ospeed	"--param sra-max-scalarization-size-Ospeed="	i	(0, 4)

# Maximum size, in storage units, of an aggregate which should be considered for scalarization when compiling for size.
##RANGE def 0
sra_max_scalarization_size_Osize	"--param sra-max-scalarization-size-Osize="	i	(0, 4)

# Maximum size of a list of values associated with each parameter for interprocedural constant propagation.
##RANGE def 8
ipa_cp_value_list_size	"--param ipa-cp-value-list-size="	i	(0, 32)

# Threshold ipa-cp opportunity evaluation that is still considered beneficial to clone.
##RANGE def 500
ipa_cp_eval_threshold	"--param ipa-cp-eval-threshold="	i	(0, 2000)

# Percentage penalty the recursive functions will receive when they are evaluated for cloning.
# def 40
ipa_cp_recursion_penalty	"--param ipa-cp-recursion-penalty="	i	(0, 100)

# Percentage penalty functions containing a single call to another function will receive when they are evaluated for cloning.
# def 15
ipa_cp_single_call_penalty	"--param ipa-cp-single-call-penalty="	i	(0, 100)

# Maximum number of aggregate content items for a parameter in jump functions and lattices.
##RANGE def 16
ipa_max_agg_items	"--param ipa-max-agg-items="	i	(0, 64)

# Compile-time bonus IPA-CP assigns to candidates which make loop bounds or strides known.
##RANGE def 64
ipa_cp_loop_hint_bonus	"--param ipa-cp-loop-hint-bonus="	i	(0, 256)

# Compile-time bonus IPA-CP assigns to candidates which make an array index known.
##RANGE def 48
ipa_cp_array_index_hint_bonus	"--param ipa-cp-array-index-hint-bonus="	i	(0, 192)

# Maximum number of statements that will be visited by IPA formal parameter analysis based on alias analysis in any given function.
##RANGE def 25000
ipa_max_aa_steps	"--param ipa-max-aa-steps="	i	(0, 100000)

# WHOPR partitioning configuration.

# Number of partitions the program should be split to.
##RANGE def 31
lto_partitions	"--param lto-partitions="	i	(1, 124)

# Minimal size of a partition for LTO (in estimated instructions).
##RANGE def 10000
lto_min_partition	"--param lto-min-partition="	i	(0, 40000)

# Maximal size of a partition for LTO (in estimated instructions).
##RANGE def 1000000
lto_max_partition	"--param lto-max-partition="	i	(0, 4000000)

# Diagnostic parameters.

# Maximum number of namespaces to search for alternatives when name lookup fails.
##RANGE def 1000
cxx_max_namespaces_for_diagnostic_help	"--param cxx-max-namespaces-for-diagnostic-help="	i	(0, 4000)

#  Maximum number of conditional store pairs that can be sunk. 
##RANGE def 2
max_stores_to_sink	"--param max-stores-to-sink="	i	(0, 8)

# Override CASE_VALUES_THRESHOLD of when to switch from doing switch
#   statements via if statements to using a table jump operation.  If the value
#   is 0, the default CASE_VALUES_THRESHOLD will be used. 
# The smallest number of different values for which it is best to use a jump-table instead of a tree of conditional branches, if 0, use the default for the machine.
##RANGE def 0
case_values_threshold	"--param case-values-threshold="	i	(0, 4)

# Data race flags for C++0x memory model compliance.
# Allow new data races on stores to be introduced.
# def 0
allow_store_data_races	"--param allow-store-data-races="	c	(0, 1)

# Reassociation width to be used by tree reassoc optimization.  

# Set the maximum number of instructions executed in parallel in reassociated tree. If 0, use the target dependent heuristic.
##RANGE def 0
tree_reassoc_width	"--param tree-reassoc-width="	i	(0, 4)

# Maximum amount of similar bbs to compare a bb with.
##RANGE def 10
max_tail_merge_comparisons	"--param max-tail-merge-comparisons="	i	(0, 40)

# Allow the store merging pass to introduce unaligned stores if it is legal to do so.
# def 1
store_merging_allow_unaligned	"--param store-merging-allow-unaligned="	i	(0, 1)

# Maximum number of constant stores to merge in the store merging pass.
##RANGE def 64
max_stores_to_merge	"--param max-stores-to-merge="	i	(2, 256)

# Maximum amount of iterations of the pass over a function.
##RANGE def 2
max_tail_merge_iterations	"--param max-tail-merge-iterations="	i	(0, 8)

# Maximum number of strings for which strlen optimization pass will
#   track string lenths. 
##RANGE def 10000
max_tracked_strlens	"--param max-tracked-strlens="	i	(0, 40000)

# Keep this in sync with the sched_pressure_algorithm enum. 
# Which -fsched-pressure algorithm to apply
# def 1
sched_pressure_algorithm	"--param sched-pressure-algorithm="	i	(1, 2)

# Maximum length of candidate scans in straight-line strength reduction. 
# def 50
max_slsr_cand_scan	"--param max-slsr-cand-scan="	i	(1, 999999)

# Enable asan stack protection.
# def 1
asan_stack	"--param asan-stack="	i	(0, 1)

# Enable asan globals protection.
# def 1
asan_globals	"--param asan-globals="	i	(0, 1)

# Enable asan store operations protection.
# def 1
asan_instrument_writes	"--param asan-instrument-writes="	i	(0, 1)

# Enable asan load operations protection.
# def 1
asan_instrument_reads	"--param asan-instrument-reads="	i	(0, 1)

# Enable asan builtin functions protection.
# def 1
asan_memintrin	"--param asan-memintrin="	i	(0, 1)

# Enable asan detection of use-after-return bugs.
# def 1
asan_use_after_return	"--param asan-use-after-return="	i	(0, 1)

# Use callbacks instead of inline code if number of accesses in function becomes greater or equal to this number.
# def 7000
asan_instrumentation_with_call_threshold	"--param asan-instrumentation-with-call-threshold="	i	(0, 24000)

# Use direct poisoning/unpoisoning instructions for variables smaller or equal to this number.
# def 256
use_after_scope_direct_emission_threshold	"--param use-after-scope-direct-emission-threshold="	i	(0, 1024)

# Maximum number of nested calls to search for control dependencies during uninitialized variable analysis.
##RANGE def 1000
uninit_control_dep_attempts	"--param uninit-control-dep-attempts="	i	(1, 4000)

# Maximum number of statements to be included into a single static constructor generated by Pointer Bounds Checker.
##RANGE def 5000
chkp_max_ctor_size	"--param chkp-max-ctor-size="	i	(100, 20000)

# Scale factor to apply to the number of statements in a threading path when comparing to the number of (scaled) blocks.
# def 2
fsm_scale_path_stmts	"--param fsm-scale-path-stmts="	i	(1, 10)

# Maximum number of arguments a PHI may have before the FSM threader will not try to thread through its block.
# def 100
fsm_maximum_phi_arguments	"--param fsm-maximum-phi-arguments="	i	(1, 999999)

# Scale factor to apply to the number of blocks in a threading path when comparing to the number of (scaled) statements.
# def 3
fsm_scale_path_blocks	"--param fsm-scale-path-blocks="	i	(1, 10)

# Maximum number of instructions to copy when duplicating blocks on a finite state automaton jump thread path.
# def 100
max_fsm_thread_path_insns	"--param max-fsm-thread-path-insns="	i	(1, 999999)

# Maximum number of basic blocks on a finite state automaton jump thread path.
# def 10
max_fsm_thread_length	"--param max-fsm-thread-length="	i	(1, 999999)

# Maximum number of new jump thread paths to create for a finite state automaton.
# def 50
max_fsm_thread_paths	"--param max-fsm-thread-paths="	i	(1, 999999)

# Chunk size of omp schedule for loops parallelized by parloops.
##RANGE def 0
parloops_chunk_size	"--param parloops-chunk-size="	i	(0, 4)

# Schedule type of omp schedule for loops parallelized by parloops (static, dynamic, guided, auto, runtime).
##ALBERTO: it's an enum parameter, I translate to integers 0-4. The params.def file however states that
# the default value needs to be provided as string, rather than numeric value
# values are (static, dynamic, guided, auto, runtime)
# def static (0)
parloops_schedule	"--param parloops-schedule="	c	(static, dynamic, guided, runtime, auto)

# Maximum recursion depth allowed when querying a property of an SSA name.
# def 3
max_ssa_name_query_depth	"--param max-ssa-name-query-depth="	i	(1, 10)

# Maximum number of insns in a basic block to consider for RTL if-conversion.
# def 10
max_rtl_if_conversion_insns	"--param max-rtl-if-conversion-insns="	i	(0, 99)

# Maximum permissible cost for the sequence that would be generated by the RTL if-conversion pass for a branch that is considered predictable.
# def 20
max_rtl_if_conversion_predictable_cost	"--param max-rtl-if-conversion-predictable-cost="	i	(0, 200)

# Maximum permissible cost for the sequence that would be generated by the RTL if-conversion pass for a branch that is considered unpredictable.
# def 40
max_rtl_if_conversion_unpredictable_cost	"--param max-rtl-if-conversion-unpredictable-cost="	i	(0, 200)

# Level of hsa debug stores verbosity
# def 0
hsa_gen_debug_stores	"--param hsa-gen-debug-stores="	i	(0, 1)

# Maximum number of may-defs visited when devirtualizing speculatively
##RANGE def 50
max_speculative_devirt_maydefs	"--param max-speculative-devirt-maydefs="	i	(0, 200)

# Maximum number of assertions to add along the default edge of a switch statement during VRP
##RANGE def 10
max_vrp_switch_assertions	"--param max-vrp-switch-assertions="	i	(0, 40)

# Enable loop epilogue vectorization using smaller vector size.
# def 0
vect_epilogues_nomask	"--param vect-epilogues-nomask="	i	(0, 1)

